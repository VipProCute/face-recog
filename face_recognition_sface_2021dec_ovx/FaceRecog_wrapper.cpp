/****************************************************************************
*   Generated by ACUITY 6.21.1
*   Match ovxlib 1.1.53
*
*   Neural Network application project entry file
****************************************************************************/
/*-------------------------------------------
                Includes
-------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#ifdef __linux__
#include <time.h>
#include <inttypes.h>
#elif defined(_WIN32)
#include <windows.h>
#include <time.h>
#endif

#define _BASETSD_H

#include "vsi_nn_pub.h"

#include <opencv2/opencv.hpp>
#include <fstream>
#include <vector>
#include <map>
#include <string>
#include <algorithm>
#include <numeric>
#include <ctime>
#include <iostream>

#include "vnn_global.h"
#include "vnn_pre_process.h"
#include "vnn_post_process_sface.h"
#include "vnn_post_process_facedetector.hpp"
#include "vnn_post_process_anfispoof.h"

extern "C" {
#include "vnn_facedetector3uint8.h"
#include "vnn_sface.h"
#include "vnn_antispoof.h"
}

#include "FaceRecog_wrapper.h"

/*-------------------------------------------
        Macros and Variables
-------------------------------------------*/
#ifdef __linux__
#define VSI_UINT64_SPECIFIER PRIu64
#elif defined(_WIN32)
#define VSI_UINT64_SPECIFIER "I64u"
#endif

#define VMX_SW_VERSION "2025JULY21.001"

/*-------------------------------------------
    Frame Processing & Access Control
-------------------------------------------*/
// Frame skip control - process every 4th frame instead of every 2nd frame
static int frame_counter = 0;
#define FRAME_SKIP_INTERVAL 4  // Changed from 2 to 4

// Access time tracking - minimum 5 minutes between access logs
static std::map<std::string, time_t> last_access_times;
#define MIN_ACCESS_INTERVAL_SECONDS (5 * 60)  // 5 minutes in seconds


/*-------------------------------------------
                  Prototype Functions
-------------------------------------------*/

float checkSpoofing(cv::Mat img);
std::vector<float> extractFeatures(cv::Mat img);

/*-------------------------------------------
    Access Logging Functions
-------------------------------------------*/
// Get current timestamp as string
std::string getCurrentTimestamp() {
    time_t now = time(0);
    char timestamp[100];
    struct tm* tm_info = localtime(&now);
    strftime(timestamp, sizeof(timestamp), "%Y-%m-%d %H:%M:%S", tm_info);
    return std::string(timestamp);
}

// Check if enough time has passed since last access for this user
bool shouldLogAccess(const std::string& username) {
    time_t current_time = time(0);
    
    auto it = last_access_times.find(username);
    if (it == last_access_times.end()) {
        // First time access for this user
        last_access_times[username] = current_time;
        return true;
    }
    
    // Check if enough time has passed
    time_t time_diff = current_time - it->second;
    if (time_diff >= MIN_ACCESS_INTERVAL_SECONDS) {
        last_access_times[username] = current_time;
        return true;
    }
    
    return false;
}

// Log access to file
void logAccess(const std::string& username, float similarity) {
    std::string timestamp = getCurrentTimestamp();
    std::string log_message = timestamp + " - User: " + username + 
                             " (Similarity: " + std::to_string(similarity) + ")\n";
    
    // Log to console
    printf("🚪 ACCESS LOG: %s", log_message.c_str());
    
    // Log to file - you can change the path here
    std::string log_file_path = "access_log.txt";  // Default: current directory
    // Alternative paths:
    // std::string log_file_path = "/path/to/logs/access_log.txt";  // Linux
    // std::string log_file_path = "C:\\logs\\access_log.txt";     // Windows
    
    std::ofstream access_log(log_file_path, std::ios::app);
    if (access_log.is_open()) {
        access_log << log_message;
        access_log.close();
    }
}

// Check frame skip - only process every FRAME_SKIP_INTERVAL frames
bool shouldProcessFrame() {
    frame_counter++;
    if (frame_counter >= FRAME_SKIP_INTERVAL) {
        frame_counter = 0;
        return true;
    }
    return false;
}
/*-------------------------------------------
                  Functions
-------------------------------------------*/

#if 1
namespace cv
{

cv::Mat getSimilarityTransformMatrix(float src[5][2]) {
    float dst[5][2] = { {38.2946f, 51.6963f}, {73.5318f, 51.5014f}, {56.0252f, 71.7366f}, {41.5493f, 92.3655f}, {70.7299f, 92.2041f} };
    float avg0 = (src[0][0] + src[1][0] + src[2][0] + src[3][0] + src[4][0]) / 5;
    float avg1 = (src[0][1] + src[1][1] + src[2][1] + src[3][1] + src[4][1]) / 5;
    //Compute mean of src and dst.
    float src_mean[2] = { avg0, avg1 };
    float dst_mean[2] = { 56.0262f, 71.9008f };
    //Subtract mean from src and dst.
    float src_demean[5][2];
    for (int i = 0; i < 2; i++)
    {
        for (int j = 0; j < 5; j++)
        {
            src_demean[j][i] = src[j][i] - src_mean[i];
        }
    }
    float dst_demean[5][2];
    for (int i = 0; i < 2; i++)
    {
        for (int j = 0; j < 5; j++)
        {
            dst_demean[j][i] = dst[j][i] - dst_mean[i];
        }
    }
    double A00 = 0.0, A01 = 0.0, A10 = 0.0, A11 = 0.0;
    for (int i = 0; i < 5; i++)
        A00 += dst_demean[i][0] * src_demean[i][0];
    A00 = A00 / 5;
    for (int i = 0; i < 5; i++)
        A01 += dst_demean[i][0] * src_demean[i][1];
    A01 = A01 / 5;
    for (int i = 0; i < 5; i++)
        A10 += dst_demean[i][1] * src_demean[i][0];
    A10 = A10 / 5;
    for (int i = 0; i < 5; i++)
        A11 += dst_demean[i][1] * src_demean[i][1];
    A11 = A11 / 5;
    cv::Mat A = (cv::Mat_<double>(2, 2) << A00, A01, A10, A11);
    double d[2] = { 1.0, 1.0 };
    double detA = A00 * A11 - A01 * A10;
    if (detA < 0)
        d[1] = -1;
    double T[3][3] = { {1.0, 0.0, 0.0}, {0.0, 1.0, 0.0}, {0.0, 0.0, 1.0} };
    cv::Mat s, u, vt, v;
    SVD::compute(A, s, u, vt);
    double smax = s.ptr<double>(0)[0]>s.ptr<double>(1)[0] ? s.ptr<double>(0)[0] : s.ptr<double>(1)[0];
    double tol = smax * 2 * FLT_MIN;
    int rank = 0;
    if (s.ptr<double>(0)[0]>tol)
        rank += 1;
    if (s.ptr<double>(1)[0]>tol)
        rank += 1;
    double arr_u[2][2] = { {u.ptr<double>(0)[0], u.ptr<double>(0)[1]}, {u.ptr<double>(1)[0], u.ptr<double>(1)[1]} };
    double arr_vt[2][2] = { {vt.ptr<double>(0)[0], vt.ptr<double>(0)[1]}, {vt.ptr<double>(1)[0], vt.ptr<double>(1)[1]} };
    double det_u = arr_u[0][0] * arr_u[1][1] - arr_u[0][1] * arr_u[1][0];
    double det_vt = arr_vt[0][0] * arr_vt[1][1] - arr_vt[0][1] * arr_vt[1][0];
    if (rank == 1)
    {
        if ((det_u*det_vt) > 0)
        {
            Mat uvt = u*vt;
            T[0][0] = uvt.ptr<double>(0)[0];
            T[0][1] = uvt.ptr<double>(0)[1];
            T[1][0] = uvt.ptr<double>(1)[0];
            T[1][1] = uvt.ptr<double>(1)[1];
        }
        else
        {
            double temp = d[1];
            d[1] = -1;
            Mat D = (Mat_<double>(2, 2) << d[0], 0.0, 0.0, d[1]);
            Mat Dvt = D*vt;
            Mat uDvt = u*Dvt;
            T[0][0] = uDvt.ptr<double>(0)[0];
            T[0][1] = uDvt.ptr<double>(0)[1];
            T[1][0] = uDvt.ptr<double>(1)[0];
            T[1][1] = uDvt.ptr<double>(1)[1];
            d[1] = temp;
        }
    }
    else
    {
        Mat D = (Mat_<double>(2, 2) << d[0], 0.0, 0.0, d[1]);
        Mat Dvt = D*vt;
        Mat uDvt = u*Dvt;
        T[0][0] = uDvt.ptr<double>(0)[0];
        T[0][1] = uDvt.ptr<double>(0)[1];
        T[1][0] = uDvt.ptr<double>(1)[0];
        T[1][1] = uDvt.ptr<double>(1)[1];
    }
    double var1 = 0.0;
    for (int i = 0; i < 5; i++)
        var1 += src_demean[i][0] * src_demean[i][0];
    var1 = var1 / 5;
    double var2 = 0.0;
    for (int i = 0; i < 5; i++)
        var2 += src_demean[i][1] * src_demean[i][1];
    var2 = var2 / 5;
    double scale = 1.0 / (var1 + var2)* (s.ptr<double>(0)[0] * d[0] + s.ptr<double>(1)[0] * d[1]);
    double TS[2];
    TS[0] = T[0][0] * src_mean[0] + T[0][1] * src_mean[1];
    TS[1] = T[1][0] * src_mean[0] + T[1][1] * src_mean[1];
    T[0][2] = dst_mean[0] - scale*TS[0];
    T[1][2] = dst_mean[1] - scale*TS[1];
    T[0][0] *= scale;
    T[0][1] *= scale;
    T[1][0] *= scale;
    T[1][1] *= scale;
    Mat transform_mat = (Mat_<double>(2, 3) << T[0][0], T[0][1], T[0][2], T[1][0], T[1][1], T[1][2]);
    return transform_mat;
}

void alignCrop(InputArray _src_img, InputArray _face_mat, OutputArray _aligned_img)
{
    Mat face_mat = _face_mat.getMat();
    float src_point[5][2];
    for (int row = 0; row < 5; ++row)
    {
        for(int col = 0; col < 2; ++col)
        {
            src_point[row][col] = face_mat.at<float>(0, row*2+col+4);
        }
    }
    Mat warp_mat = getSimilarityTransformMatrix(src_point);
    warpAffine(_src_img, _aligned_img, warp_mat, Size(112, 112), INTER_LINEAR);
}
}   //namespace cv
#endif
#if ANTI_SPOOFING
static void vnn_ReleaseNeuralNetworkAntiSpoof
    (
    vsi_nn_graph_t *graph
    )
{
    vnn_ReleaseAntiSpoof( graph, TRUE );
    if (vnn_UseImagePreprocessNode())
    {
        vnn_ReleaseBufferImage();
    }
}
#endif
static void vnn_ReleaseNeuralNetworkSface
    (
    vsi_nn_graph_t *graph
    )
{
    vnn_ReleaseSface( graph, TRUE );
    if (vnn_UseImagePreprocessNode())
    {
        vnn_ReleaseBufferImage();
    }
}
#if ANTI_SPOOFING
static float vnn_PostProcessNeuralNetworkAntiSpoof
    (
    vsi_nn_graph_t *graph
    )
{
    return vnn_PostProcessAntiSpoof( graph );
}
#endif
static vsi_status vnn_PostProcessNeuralNetworkSface
    (
    vsi_nn_graph_t *graph
    )
{
    return vnn_PostProcessSface( graph );
}

#define BILLION                                 1000000000
static uint64_t get_perf_count()
{
#if defined(__linux__) || defined(__ANDROID__) || defined(__QNX__) || defined(__CYGWIN__)
    struct timespec ts;

    clock_gettime(CLOCK_MONOTONIC, &ts);

    return (uint64_t)((uint64_t)ts.tv_nsec + (uint64_t)ts.tv_sec * BILLION);
#elif defined(_WIN32) || defined(UNDER_CE)
    LARGE_INTEGER freq;
    LARGE_INTEGER ln;

    QueryPerformanceFrequency(&freq);
    QueryPerformanceCounter(&ln);

    return (uint64_t)(ln.QuadPart * BILLION / freq.QuadPart);
#endif
}

static vsi_status vnn_VerifyGraph
    (
    vsi_nn_graph_t *graph
    )
{
    vsi_status status = VSI_FAILURE;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    /* Verify graph */
    printf("Verify...\n");
    tmsStart = get_perf_count();
    status = vsi_nn_VerifyGraph( graph );
    TEST_CHECK_STATUS(status, final);
    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Verify Graph: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return status;
}

static vsi_status vnn_ProcessGraph
    (
    vsi_nn_graph_t *graph
    )
{
    vsi_status status = VSI_FAILURE;
    int32_t i,loop;
    char *loop_s;
    uint64_t tmsStart, tmsEnd, sigStart, sigEnd;
    float msVal, usVal;

    status = VSI_FAILURE;
    loop = 1; /* default loop time is 1 */
    loop_s = getenv("VNN_LOOP_TIME");
    if(loop_s)
    {
        loop = atoi(loop_s);
    }

    /* Run graph */
    // tmsStart = get_perf_count();
    // printf("Start run graph [%d] times...\n", loop);
    for(i = 0; i < loop; i++)
    {
        // sigStart = get_perf_count();
#ifdef VNN_APP_ASYNC_RUN
        status = vsi_nn_AsyncRunGraph( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Async Run graph the %d time fail\n", i);
        }
        TEST_CHECK_STATUS( status, final );

        //do something here...

        status = vsi_nn_AsyncRunWait( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Wait graph the %d time fail\n", i);
        }
#else
        status = vsi_nn_RunGraph( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Run graph the %d time fail\n", i);
        }
#endif
        TEST_CHECK_STATUS( status, final );

        // sigEnd = get_perf_count();
        // msVal = (sigEnd - sigStart)/(float)1000000;
        // usVal = (sigEnd - sigStart)/(float)1000;
        // printf("Run the %u time: %.2fms or %.2fus\n", (i + 1), msVal, usVal);
    }
    // tmsEnd = get_perf_count();
    // msVal = (tmsEnd - tmsStart)/(float)1000000;
    // usVal = (tmsEnd - tmsStart)/(float)1000;
    // printf("vxProcessGraph execution time:\n");
    // printf("Total   %.2fms or %.2fus\n", msVal, usVal);
    // printf("Average %.2fms or %.2fus\n", ((float)usVal)/1000/loop, ((float)usVal)/loop);

final:
    return status;
}

static vsi_status vnn_PreProcessNeuralNetwork
    (
    vsi_nn_graph_t *graph,
    // int argc,
    // char **argv,
    uint32_t input_num,
    uint8_t *input_buf
    )
{
    /*
     * argv0:   execute file
     * argv1:   data file
     * argv2~n: inputs n file
     */
    // const char **inputs = (const char **)argv + 2;
    // uint32_t input_num = argc - 2;

    return vnn_PreProcess( graph, /*inputs,*/ input_num, input_buf );
}
#if 1
// Add by NhanTran
static vsi_nn_graph_t *vnn_CreateNeuralNetworkFacedetector3Uint8
    (
    const char *data_file_name
    )
{
    vsi_nn_graph_t *graph = NULL;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    tmsStart = get_perf_count();
    graph = vnn_CreateFacedetector3Uint8( data_file_name, NULL,
                      vnn_GetPreProcessMap(), vnn_GetPreProcessMapCount(),
                      vnn_GetPostProcessMap(), vnn_GetPostProcessMapCount() );
    TEST_CHECK_PTR(graph, final);

    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("%s():%d\n", __FUNCTION__, __LINE__);
    printf("Create Neural Network: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return graph;
}

static void vnn_ReleaseNeuralNetworkFacedetector3Uint8
    (
    vsi_nn_graph_t *graph
    )
{
    vnn_ReleaseFacedetector3Uint8( graph, TRUE );
    if (vnn_UseImagePreprocessNode())
    {
        vnn_ReleaseBufferImage();
    }
}

static vsi_status vnn_PostProcessNeuralNetworkFaceDetector3Uint8
    (
    vsi_nn_graph_t *graph,
    std::vector<FaceObject>& faces
    )
{
    return vnn_PostProcessFacedetector3Uint8( graph, faces );
}
#if ANTI_SPOOFING
static vsi_nn_graph_t *vnn_CreateNeuralNetworkAntiSpoof
    (
    const char *data_file_name
    )
{
    vsi_nn_graph_t *graph = NULL;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    tmsStart = get_perf_count();
    graph = vnn_CreateAntiSpoof( data_file_name, NULL,
                      vnn_GetPreProcessMap(), vnn_GetPreProcessMapCount(),
                      vnn_GetPostProcessMap(), vnn_GetPostProcessMapCount() );
    TEST_CHECK_PTR(graph, final);

    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Create Neural Network: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return graph;
}
#endif
#endif

static vsi_nn_graph_t *vnn_CreateNeuralNetworkSface
    (
    const char *data_file_name
    )
{
    vsi_nn_graph_t *graph = NULL;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    tmsStart = get_perf_count();
    graph = vnn_CreateSface( data_file_name, NULL,
                      vnn_GetPreProcessMap(), vnn_GetPreProcessMapCount(),
                      vnn_GetPostProcessMap(), vnn_GetPostProcessMapCount() );
    TEST_CHECK_PTR(graph, final);

    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Create Neural Network: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return graph;
}


uint8_t* pre_process_get_buffer_from_mat(cv::Mat matImg, uint32_t *buffer_size) {
    uint8_t *data_buffer = NULL;
    if (!matImg.empty()) {
        uint32_t buff_size = matImg.cols * matImg.rows * sizeof(uint8_t)*matImg.channels();

        data_buffer = malloc(buff_size);

        if (data_buffer) {
            memcpy(data_buffer, matImg.data, buff_size);
            // *buffer_size = buff_size;
        } else
            return nullptr;
    }
    // printf("[%s()]::[%d] buff_size = %d\n", __FUNCTION__, __LINE__, buff_size);
    return data_buffer;
}

#if 1
// Add by NhanTran
vsi_status statusFaceDetect = VSI_FAILURE;
vsi_status statusSface = VSI_FAILURE;
#if ANTI_SPOOFING
vsi_status statusAntiSpf = VSI_FAILURE;
#endif
vsi_nn_graph_t* graphFaceDetect = nullptr;
vsi_nn_graph_t* graphSface = nullptr;
#if ANTI_SPOOFING
vsi_nn_graph_t* graphAntiSpf = nullptr;
#endif
int32_t init_neural_networks() {
    const char* model_name_facedetect = nullptr;
    const char* model_name_sface = nullptr;
#if ANTI_SPOOFING
    const char* model_name_anti_spf = nullptr;
#endif
    std::cout << "S/W Version : " << VMX_SW_VERSION << std::endl;
    model_name_facedetect = "network_binary_face_detector.nb";
    model_name_sface = "sface.export.data";
    // model_name_sface = "facenet512.export.data";
#if ANTI_SPOOFING
    model_name_anti_spf = "anti-spoof-mn3.export.data";
#endif
    std::cout << "model_name_facedetect: " << model_name_facedetect << std::endl;
    std::cout << "model_name_sface: " << model_name_sface << std::endl;    
#if ANTI_SPOOFING
    std::cout << "model_name_anti_spf: " << model_name_anti_spf << std::endl;    
#endif
    graphFaceDetect = vnn_CreateNeuralNetworkFacedetector3Uint8(model_name_facedetect);
    graphSface = vnn_CreateNeuralNetworkSface(model_name_sface);
#if ANTI_SPOOFING
    graphAntiSpf = vnn_CreateNeuralNetworkAntiSpoof(model_name_anti_spf);
#endif
    if (!graphFaceDetect) {
        std::cerr << "Failed to create face_detector neural network." << std::endl;
        return -1;
    } else if (!graphSface) {
        std::cerr << "Failed to create SFace neural network." << std::endl;
        return -1;
    } 
#if ANTI_SPOOFING
    else if (!graphAntiSpf) {
        std::cerr << "Failed to create AntiSpoof neural network." << std::endl;
        return -1;
    }
#endif
    statusFaceDetect = vnn_VerifyGraph(graphFaceDetect);
    statusSface = vnn_VerifyGraph(graphSface);
#if ANTI_SPOOFING
    statusAntiSpf = vnn_VerifyGraph(graphAntiSpf);
#endif
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Graph (FaceDetect) verification failed." << std::endl;
        vnn_ReleaseNeuralNetworkFacedetector3Uint8(graphFaceDetect);
        return -1;
    } else if (statusSface != VSI_SUCCESS) {
        std::cerr << "Graph (SFace) verification failed." << std::endl;
        vnn_ReleaseNeuralNetworkSface(statusSface);
        return -1;
    } 
#if ANTI_SPOOFING    
    else if (statusAntiSpf != VSI_SUCCESS) {
        std::cerr << "Graph (AntiSpoof) verification failed." << std::endl;
        vnn_ReleaseNeuralNetworkAntiSpoof(statusAntiSpf);
        return -1;
    }
#endif
    return VSI_SUCCESS;
}

#if 0
cv::Mat resizeKeepAspectRatio(const cv::Mat &input, const cv::Size &dstSize, const cv::Scalar& bgcolor)
{
    cv::Mat output;

    double h1 = dstSize.width * (input.rows/(double)input.cols);
    double w2 = dstSize.height * (input.cols/(double)input.rows);
    
    // initially no borders
    int top = 0;
    int bottom = 0;
    int left = 0;
    int right = 0;
    if (h1 <= dstSize.height)
    {   // Scale based on width
        // only vertical borders
        top = (dstSize.height - h1) / 2;
        bottom = top;
        cv::resize( input, output, cv::Size(dstSize.width, h1));
    } 
    else
    {   // Scale based on height
        // only horizontal borders
        left = (dstSize.width - w2) / 2;
        right = left;
        cv::resize( input, output, cv::Size(w2, dstSize.height));
    }
    cv::copyMakeBorder(output, output, top, bottom, left, right, cv::BORDER_CONSTANT, bgcolor);
    return output;
}
#else
cv::Mat resizeKeepAspectRatio(const cv::Mat &input, const cv::Size &dstSize, const cv::Scalar &bgcolor) {

    cv::Mat output;
    double h_scale = (double)dstSize.height / input.rows;
    double w_scale = (double)dstSize.width / input.cols;
    double scale = std::min(h_scale, w_scale);

    int new_rows = static_cast<int>(input.rows * scale);
    int new_cols = static_cast<int>(input.cols * scale);

    cv::resize(input, output, cv::Size(new_cols, new_rows), 0, 0, cv::INTER_AREA);

    int top = (dstSize.height - new_rows) / 2;
    int bottom = dstSize.height - new_rows - top;
    int left = (dstSize.width - new_cols) / 2;
    int right = dstSize.width - new_cols - left;

    cv::copyMakeBorder(output, output, top, bottom, left, right, cv::BORDER_CONSTANT, bgcolor);
    return output;
}

#endif
std::tuple<uint8_t, std::vector<float>> register_user(cv::Mat img) {
    vsi_status status = VSI_FAILURE;
    std::vector<float> facial_feature = {};

    if (img.empty()) {
        std::cout << "Failed to read frame from camera." << std::endl;
        return std::make_tuple(statusFaceDetect, facial_feature);
    }

    // float x_scale = float(img.cols) / float(IMAGE_WIDTH);
    // float y_scale = float(img.rows) / float(IMAGE_HEIGHT);
    // std::cout << x_scale << std::endl;
    // std::cout << y_scale << std::endl;

    // cv::resize(img, img, cv::Size(IMAGE_WIDTH, IMAGE_HEIGHT));
    cv::Size dstSize(IMAGE_WIDTH, IMAGE_HEIGHT);
    cv::Scalar paddingColor(0, 0, 0); // Black padding color (BGR)
    img = resizeKeepAspectRatio(img, dstSize, paddingColor);
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);
    
    // uint8_t* pRgb = new uint8_t[img.rows * img.cols * 3];
    // Mat_to_array(img, pRgb);
    uint8_t *img_buffer = NULL;
    // uint32_t *img_buffer_size = 0;
    
    // img_buffer = pre_process_get_buffer_from_mat(img, img_buffer_size);
    if (img.isContinuous())
        img_buffer = img.data;

    //mod ted for recongnition and register image command, 20241115
    //status = vnn_PreProcessNeuralNetwork(graph, argc, argv, pRgb);
    statusFaceDetect = vnn_PreProcessNeuralNetwork(graphFaceDetect, 1, img_buffer);

// #if 1
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Pre-processing failed." << std::endl;
        // delete[] pRgb;
        return std::make_tuple(statusFaceDetect, facial_feature);
    }

    statusFaceDetect = vnn_ProcessGraph(graphFaceDetect);       
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Graph processing failed." << std::endl;
        // delete[] pRgb;
        return std::make_tuple(statusFaceDetect, facial_feature);
    }

    std::vector<FaceObject> faces;        
    statusFaceDetect = vnn_PostProcessNeuralNetworkFaceDetector3Uint8(graphFaceDetect, faces);       
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Post-processing failed." << std::endl;
        // delete[] pRgb;
        return std::make_tuple(statusFaceDetect, facial_feature);
    }

    std::cout << __FUNCTION__ << "():" << __LINE__ << std::endl;
    printf("The number of faces: %ld\n", faces.size());
    if (faces.size() == 1) {
        auto& face = faces[0];
        int x1, y1, x2, y2;
        x1 = std::max(0, std::min(face.rect.x, img.cols - 1));
        y1 = std::max(0, std::min(face.rect.y, img.rows - 1));
        x2 = std::max(0, std::min(face.rect.width, img.cols - 1));
        y2 = std::max(0, std::min(face.rect.height, img.rows - 1));
        int w = x2 - x1;
        int h = y2 - y1;
        cv::Rect b_box(x1, y1, w, h);
        cv::Mat detected_faces[1];
        detected_faces[0] = img(b_box);
#if 0
        char saved_face[128];
        // sprintf(saved_face, "detected_face_%d.jpg", i);
        sprintf(saved_face, "detected_face_.jpg");
        if (!detected_faces[0].empty()) {
            cv::imwrite(saved_face, detected_faces[0]);
        }
#endif
#if 0
        // cv::Mat face_image = faces.row(0);
        cv::Mat face_image = detected_faces[0];
        cv::Mat target_aligned;
        alignCrop(img, face_image, target_aligned);
        char aligned_face[128];
        // sprintf(saved_face, "detected_face_%d.jpg", i);
        sprintf(aligned_face, "aligned_face.jpg");
        if (!target_aligned.empty()) {
            cv::imwrite(aligned_face, target_aligned);
        }
#endif
        detected_faces[0] = resizeKeepAspectRatio(detected_faces[0], cv::Size(112, 112), paddingColor);

        facial_feature = extractFeatures(detected_faces[0]);
        // std::cout << "facial_feature.size(): " << facial_feature.size() << std::endl;
        return std::make_tuple(statusFaceDetect, facial_feature);
    }
    else
    {
        std::cerr << "Please capture only ONE person." << std::endl;
        return std::make_tuple(VSI_FAILURE, facial_feature);
    }

    // return std::make_tuple(statusFaceDetect, facial_feature);
}
std::tuple<uint16_t, uint16_t, uint16_t, uint16_t, float, std::vector<float>> detect_face(cv::Mat img) {

    std::tuple<uint16_t, uint16_t, uint16_t, uint16_t, float, std::vector<float>> empty_result = {0, 0, 0, 0, -1, {}};
    std::vector<float> facial_feature = {};
    float spoof_thresh = 0.4;
    float spoof_confidence = 1;

    // Frame skip check - only process every 4th frame
    if (!shouldProcessFrame()) {
        printf("⏭️  Skipping frame %d (processing every %d frames)\n", frame_counter, FRAME_SKIP_INTERVAL);
        return empty_result;
    }
    
    printf("🎯 Processing frame %d\n", frame_counter);

    if (img.empty()) {
        std::cout << "Failed to read frame from camera." << std::endl;
        return empty_result;
    }

    // float x_scale = float(img.cols) / float(IMAGE_WIDTH);
    // float y_scale = float(img.rows) / float(IMAGE_HEIGHT);
    // std::cout << x_scale << std::endl;
    // std::cout << y_scale << std::endl;

    // cv::resize(img, img, cv::Size(IMAGE_WIDTH, IMAGE_HEIGHT));
    // cv::Size dstSize(IMAGE_WIDTH, IMAGE_HEIGHT);
    cv::Scalar paddingColor(0, 0, 0); // Black padding color (BGR)
    // img = resizeKeepAspectRatio(img, dstSize, paddingColor);
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);

    // uint8_t* pRgb = new uint8_t[img.rows * img.cols * 3];
    // Mat_to_array(img, pRgb);
    uint8_t *img_buffer = NULL;
    // uint32_t *img_buffer_size = 0;
    
    // img_buffer = pre_process_get_buffer_from_mat(img, img_buffer_size);
    if (img.isContinuous())
        img_buffer = img.data;

    //mod ted for recongnition and register image command, 20241115
    //status = vnn_PreProcessNeuralNetwork(graph, argc, argv, pRgb);
    statusFaceDetect = vnn_PreProcessNeuralNetwork(graphFaceDetect, 1, img_buffer);

    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Pre-processing failed." << std::endl;
        // delete[] pRgb;
        return empty_result;
    }

    statusFaceDetect = vnn_ProcessGraph(graphFaceDetect);       
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Graph processing failed." << std::endl;
        // delete[] pRgb;
        return empty_result;
    }

    std::vector<FaceObject> faces;        
    statusFaceDetect = vnn_PostProcessNeuralNetworkFaceDetector3Uint8(graphFaceDetect, faces);       
    if (statusFaceDetect != VSI_SUCCESS) {
        std::cerr << "Post-processing failed." << std::endl;
        // delete[] pRgb;
        return empty_result;
    }

#if 1
    printf("The number of faces: %ld\n", faces.size());

    if (faces.size() > 0) {
        auto& face = faces[0];
        uint16_t left, top, right, bottom;
        uint16_t x1, y1, x2, y2;

        x1 = left = std::max(0, std::min(face.rect.x, img.cols - 1));
        y1 = top = std::max(0, std::min(face.rect.y, img.rows - 1));
        x2 = right = std::max(0, std::min(face.rect.width, img.cols - 1));
        y2 = bottom = std::max(0, std::min(face.rect.height, img.rows - 1));

        // return std::make_tuple(uint16_t(left * x_scale), uint16_t(top * y_scale), uint16_t(right * x_scale), uint16_t(bottom * y_scale), "ahihi");
        int w = x2 - x1;
        int h = y2 - y1;
        cv::Rect b_box(x1, y1, w, h);
        cv::Mat detected_faces[1];
        detected_faces[0] = img(b_box);
        detected_faces[0] = resizeKeepAspectRatio(detected_faces[0], cv::Size(112, 112), paddingColor);

        // detected_faces[0].convertTo(detected_faces[0], CV_32FC3, 1.0 / 255.0f);
        // detected_faces[0] -= cv::Scalar(0.485, 0.456, 0.406);
        // detected_faces[0] /= cv::Scalar(0.229, 0.224, 0.225);


        facial_feature = extractFeatures(detected_faces[0]);
        // std::cout << "facial_feature.size(): " << facial_feature.size() << std::endl;
    #if ANTI_SPOOFING
        cv::Mat anti_spf_input = img(b_box);
        // cv::resize(anti_spf_input, anti_spf_input, cv::Size(128, 128), 0, 0, cv::INTER_CUBIC);
        // cv::normalize(anti_spf_input, anti_spf_input, 1.0, 0.0, cv::NORM_MINMAX, CV_32FC3);
        // cv::normalize(anti_spf_input, anti_spf_input, 0.0, 1.0, cv::NORM_MINMAX, CV_32FC3);
        // anti_spf_input.convertTo(anti_spf_input, CV_32FC3, 1.0 / 255.0f, 0);

        // printf("[%s()]::[%d] anti_spf_input.rows = %d\n", __FUNCTION__, __LINE__, anti_spf_input.rows);
        // printf("[%s()]::[%d] anti_spf_input.cols = %d\n", __FUNCTION__, __LINE__, anti_spf_input.cols);
        anti_spf_input = resizeKeepAspectRatio(anti_spf_input, cv::Size(128, 128), paddingColor);
        anti_spf_input.convertTo(anti_spf_input, CV_32FC3, 1.0 / 255.0f);
        // anti_spf_input -= cv::Scalar(0.485, 0.456, 0.406);
        // anti_spf_input /= cv::Scalar(0.229, 0.224, 0.225);
        cv::Scalar mean(0.485, 0.456, 0.406);
        cv::Scalar std(0.229, 0.224, 0.225);
        anti_spf_input = (anti_spf_input - mean) / std;
        spoof_confidence = checkSpoofing(anti_spf_input);
        // printf("[%s()]::[%d] spoof_confidence = %f\n", __FUNCTION__, __LINE__, spoof_confidence);

        // ✅ FACE RECOGNITION & ACCESS LOGGING: Only if face is real
        if (spoof_confidence > spoof_thresh && !facial_feature.empty()) {
            printf("=== FACE RECOGNITION SEARCH ===\n");
            // Note: Add face database search here if available
            // For now, we'll use a dummy username for demonstration
            std::string dummy_username = "TestUser_" + std::to_string(std::rand() % 100);
            float dummy_similarity = 0.75f + (std::rand() % 25) / 100.0f;
            
            printf("✅ FACE RECOGNIZED: %s (confidence: %.4f)\n", dummy_username.c_str(), dummy_similarity);
            
            // ✅ ACCESS LOGGING: Check if we should log this access
            if (shouldLogAccess(dummy_username)) {
                logAccess(dummy_username, dummy_similarity);
                printf("📝 Access logged for user: %s\n", dummy_username.c_str());
            } else {
                printf("⏰ Access not logged (too soon since last access for %s)\n", dummy_username.c_str());
            }
            printf("===============================\n");
        }

        return std::make_tuple(left, top, right, bottom, spoof_confidence, facial_feature);
    #endif
        return std::make_tuple(left, top, right, bottom, spoof_confidence, facial_feature);

    } else {
        std::cerr << "Please capture person FACE." << std::endl;
        return empty_result;
    }

#endif

}
#endif

std::vector<float> extractFeatures(cv::Mat img) {

    vsi_status status = VSI_FAILURE;
    uint8_t *img_buffer = NULL;
    // uint32_t *img_buffer_size = 0;
    std::vector<float> feature;

    
    // img_buffer = pre_process_get_buffer_from_mat(img, img_buffer_size);
    if (img.isContinuous())
        img_buffer = img.data;

    /* Pre process the image data */
    // uint32_t input_num = 1;
    // printf("[%s()]::[%d] graphSface->input.num = %d\n", __FUNCTION__, __LINE__, graphSface->input.num);
    status = vnn_PreProcessNeuralNetwork( graphSface, 1, img_buffer );
    TEST_CHECK_STATUS( status, final );

    /* Process graph */
    status = vnn_ProcessGraph( graphSface );
    TEST_CHECK_STATUS( status, final );

    if(VNN_APP_DEBUG)
    {
        /* Dump all node outputs */
        vsi_nn_DumpGraphNodeOutputs(graphSface, "./network_dump", NULL, 0, TRUE, 0);
    }

    /* Post process output data */
    // status = vnn_PostProcessNeuralNetworkSface( graphSface );
    // TEST_CHECK_STATUS( status, final );
    feature = vnn_PostProcessSfaceExtractFeature( graphSface );

final:
    // vnn_ReleaseNeuralNetworkSface( graphSface );
    fflush(stdout);
    fflush(stderr);
    // return status;
    return feature;

}
#if ANTI_SPOOFING
float checkSpoofing(cv::Mat img) {
    vsi_status status = VSI_FAILURE;
    uint8_t *img_buffer = NULL;
    // uint32_t *img_buffer_size = 0;

    
    // img_buffer = pre_process_get_buffer_from_mat(img, img_buffer_size);
    if (img.isContinuous())
        img_buffer = img.data;

    /* Pre process the image data */
    // uint32_t input_num = 1;
    // printf("[%s()]::[%d] graphAntiSpf->input.num = %d\n", __FUNCTION__, __LINE__, graphAntiSpf->input.num);
    status = vnn_PreProcessNeuralNetwork( graphAntiSpf, 1, img_buffer );
    TEST_CHECK_STATUS( status, final );

    /* Process graph */
    status = vnn_ProcessGraph( graphAntiSpf );
    TEST_CHECK_STATUS( status, final );

    if(VNN_APP_DEBUG)
    {
        /* Dump all node outputs */
        vsi_nn_DumpGraphNodeOutputs(graphAntiSpf, "./network_dump", NULL, 0, TRUE, 0);
    }

    /* Post process output data */
    // TEST_CHECK_STATUS( status, final );

    return vnn_PostProcessNeuralNetworkAntiSpoof(graphAntiSpf);

final:
    // vnn_ReleaseNeuralNetworkAntiSpoof( graphAntiSpf );
    fflush(stdout);
    fflush(stderr);
    return -1;
}
#endif
