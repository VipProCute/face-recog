/****************************************************************************
*   Generated by ACUITY 6.21.1
*   Match ovxlib 1.1.53
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_antispoof.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(vsi_size_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        if( NULL == data ) {\
            goto error;\
        }\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        if ( enable_from_handle )\
        {\
            _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        else\
        {\
            _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (189)
#define NET_NORM_TENSOR_NUM     (2)
#define NET_CONST_TENSOR_NUM    (146)
#define NET_VIRTUAL_TENSOR_NUM  (189)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    ssize_t ret;
    size_t size;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = VSI_FSEEK(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    size = fread(data, 1, sz, fp);
    if (size != sz || size == 0)
    {
        free(data);
        data = NULL;
        VSILOGE("Read file to buffer failed.");
    }
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateAntiSpoof
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    char *                  use_from_handle = NULL;
    int32_t                 enable_pre_post_process = 0;
    int32_t                 enable_from_handle = 0;
    vsi_bool                sort = FALSE;
    vsi_bool                inference_with_nbg = FALSE;
    char*                   pos = NULL;

    vsi_size_t shape_1[] = { 72, 1 };
    vsi_size_t shape_2[] = { 1, 1, 72, 1 };
    vsi_size_t shape_3[] = { 120, 1 };
    vsi_size_t shape_4[] = { 1, 1, 120, 1 };
    vsi_size_t shape_5[] = { 120, 1 };
    vsi_size_t shape_6[] = { 1, 1, 120, 1 };
    vsi_size_t shape_7[] = { 480, 1 };
    vsi_size_t shape_8[] = { 1, 1, 480, 1 };
    vsi_size_t shape_9[] = { 672, 1 };
    vsi_size_t shape_10[] = { 1, 1, 672, 1 };
    vsi_size_t shape_11[] = { 672, 1 };
    vsi_size_t shape_12[] = { 1, 1, 672, 1 };
    vsi_size_t shape_13[] = { 960, 1 };
    vsi_size_t shape_14[] = { 1, 1, 960, 1 };
    vsi_size_t shape_15[] = { 960, 1 };
    vsi_size_t shape_16[] = { 1, 1, 960, 1 };
    vsi_size_t shape_17[] = { -1, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );
    memset( &node, 0, sizeof( vsi_nn_node_t * ) * NET_NODE_NUM );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    pos = strstr(data_file_name, ".nb");
    if( pos && strcmp(pos, ".nb") == 0 )
    {
        inference_with_nbg = TRUE;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }
    use_from_handle = getenv( "VSI_USE_FROM_HANDLE" );
    if ( use_from_handle )
    {
        enable_from_handle = atoi(use_from_handle);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 1 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/
    if( !inference_with_nbg )
    {

    /*-----------------------------------------
      lid       - Initializer_766_54
      var       - node[0]
      name      - Initializer_766
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_VARIABLE, 1, 1, 54);

    /*-----------------------------------------
      lid       - Initializer_763_66
      var       - node[1]
      name      - Initializer_763
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_VARIABLE, 1, 1, 66);

    /*-----------------------------------------
      lid       - Initializer_673_69
      var       - node[2]
      name      - Initializer_673
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_VARIABLE, 1, 1, 69);

    /*-----------------------------------------
      lid       - Initializer_719_74
      var       - node[3]
      name      - Initializer_719
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_VARIABLE, 1, 1, 74);

    /*-----------------------------------------
      lid       - Initializer_670_84
      var       - node[4]
      name      - Initializer_670
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_VARIABLE, 1, 1, 84);

    /*-----------------------------------------
      lid       - Initializer_716_88
      var       - node[5]
      name      - Initializer_716
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_VARIABLE, 1, 1, 88);

    /*-----------------------------------------
      lid       - Initializer_626_130
      var       - node[6]
      name      - Initializer_626
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_VARIABLE, 1, 1, 130);

    /*-----------------------------------------
      lid       - Initializer_580_146
      var       - node[7]
      name      - Initializer_580
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_VARIABLE, 1, 1, 146);

    /*-----------------------------------------
      lid       - Initializer_623_153
      var       - node[8]
      name      - Initializer_623
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_VARIABLE, 1, 1, 153);

    /*-----------------------------------------
      lid       - Initializer_577_157
      var       - node[9]
      name      - Initializer_577
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_VARIABLE, 1, 1, 157);

    /*-----------------------------------------
      lid       - Initializer_463_272
      var       - node[10]
      name      - Initializer_463
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_VARIABLE, 1, 1, 272);

    /*-----------------------------------------
      lid       - Initializer_390_281
      var       - node[11]
      name      - Initializer_390
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_VARIABLE, 1, 1, 281);

    /*-----------------------------------------
      lid       - Initializer_426_284
      var       - node[12]
      name      - Initializer_426
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_VARIABLE, 1, 1, 284);

    /*-----------------------------------------
      lid       - Initializer_460_287
      var       - node[13]
      name      - Initializer_460
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_VARIABLE, 1, 1, 287);

    /*-----------------------------------------
      lid       - Initializer_423_292
      var       - node[14]
      name      - Initializer_423
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_VARIABLE, 1, 1, 292);

    /*-----------------------------------------
      lid       - Initializer_387_296
      var       - node[15]
      name      - Initializer_387
      operation - variable
      input     - 
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_VARIABLE, 1, 1, 296);

    /*-----------------------------------------
      lid       - Conv_Conv_0_333
      var       - node[16]
      name      - Conv_Conv_0
      operation - convolution
      input     - [128, 128, 3, 1]
      filter    - [3, 3, 3, 16]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV2D, 3, 1, 333);
    node[16]->nn_param.conv2d.ksize[0] = 3;
    node[16]->nn_param.conv2d.ksize[1] = 3;
    node[16]->nn_param.conv2d.weights = 16;
    node[16]->nn_param.conv2d.stride[0] = 2;
    node[16]->nn_param.conv2d.stride[1] = 2;
    node[16]->nn_param.conv2d.pad[0] = 1;
    node[16]->nn_param.conv2d.pad[1] = 1;
    node[16]->nn_param.conv2d.pad[2] = 1;
    node[16]->nn_param.conv2d.pad[3] = 1;
    node[16]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[16]->nn_param.conv2d.group = 1;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->nn_param.conv2d.multiplier = 0;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_3_338_Clip_Clip_4_334_relun_388_Div_Div_6_331_Mul_Mul_7_328
      var       - node[17]
      name      - hard_swish
      operation - hard_swish
      input     - [64, 64, 16, 1]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_SWISH, 1, 1, 328);
    node[17]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_8_339
      var       - node[18]
      name      - Conv_Conv_8
      operation - convolution
      input     - [64, 64, 16, 1]
      filter    - [3, 3, 16, 1]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV2D, 3, 1, 339);
    node[18]->nn_param.conv2d.ksize[0] = 3;
    node[18]->nn_param.conv2d.ksize[1] = 3;
    node[18]->nn_param.conv2d.weights = 16;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 1;
    node[18]->nn_param.conv2d.pad[1] = 1;
    node[18]->nn_param.conv2d.pad[2] = 1;
    node[18]->nn_param.conv2d.pad[3] = 1;
    node[18]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[18]->nn_param.conv2d.group = 16;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->nn_param.conv2d.multiplier = 1;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_10_336
      var       - node[19]
      name      - Relu_Relu_10
      operation - relu
      input     - [64, 64, 16, 1]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_RELU, 1, 1, 336);

    /*-----------------------------------------
      lid       - Conv_Conv_11_332
      var       - node[20]
      name      - Conv_Conv_11
      operation - convolution
      input     - [64, 64, 16, 1]
      filter    - [1, 1, 16, 16]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_CONV2D, 3, 1, 332);
    node[20]->nn_param.conv2d.ksize[0] = 1;
    node[20]->nn_param.conv2d.ksize[1] = 1;
    node[20]->nn_param.conv2d.weights = 16;
    node[20]->nn_param.conv2d.stride[0] = 1;
    node[20]->nn_param.conv2d.stride[1] = 1;
    node[20]->nn_param.conv2d.pad[0] = 0;
    node[20]->nn_param.conv2d.pad[1] = 0;
    node[20]->nn_param.conv2d.pad[2] = 0;
    node[20]->nn_param.conv2d.pad[3] = 0;
    node[20]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[20]->nn_param.conv2d.group = 1;
    node[20]->nn_param.conv2d.dilation[0] = 1;
    node[20]->nn_param.conv2d.dilation[1] = 1;
    node[20]->nn_param.conv2d.multiplier = 0;
    node[20]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[20]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_13_327
      var       - node[21]
      name      - Add_Add_13
      operation - add
      input     - [64, 64, 16, 1]
                  [64, 64, 16, 1]
      output    - [64, 64, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_ADD, 2, 1, 327);

    /*-----------------------------------------
      lid       - Conv_Conv_14_326
      var       - node[22]
      name      - Conv_Conv_14
      operation - convolution
      input     - [64, 64, 16, 1]
      filter    - [1, 1, 16, 64]
      output    - [64, 64, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 326);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 64;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 0;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_16_323
      var       - node[23]
      name      - Relu_Relu_16
      operation - relu
      input     - [64, 64, 64, 1]
      output    - [64, 64, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_RELU, 1, 1, 323);

    /*-----------------------------------------
      lid       - Conv_Conv_17_321
      var       - node[24]
      name      - Conv_Conv_17
      operation - convolution
      input     - [64, 64, 64, 1]
      filter    - [3, 3, 64, 1]
      output    - [32, 32, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONV2D, 3, 1, 321);
    node[24]->nn_param.conv2d.ksize[0] = 3;
    node[24]->nn_param.conv2d.ksize[1] = 3;
    node[24]->nn_param.conv2d.weights = 64;
    node[24]->nn_param.conv2d.stride[0] = 2;
    node[24]->nn_param.conv2d.stride[1] = 2;
    node[24]->nn_param.conv2d.pad[0] = 1;
    node[24]->nn_param.conv2d.pad[1] = 1;
    node[24]->nn_param.conv2d.pad[2] = 1;
    node[24]->nn_param.conv2d.pad[3] = 1;
    node[24]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[24]->nn_param.conv2d.group = 64;
    node[24]->nn_param.conv2d.dilation[0] = 1;
    node[24]->nn_param.conv2d.dilation[1] = 1;
    node[24]->nn_param.conv2d.multiplier = 1;
    node[24]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[24]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[24]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_19_315
      var       - node[25]
      name      - Relu_Relu_19
      operation - relu
      input     - [32, 32, 64, 1]
      output    - [32, 32, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_RELU, 1, 1, 315);

    /*-----------------------------------------
      lid       - Conv_Conv_20_310
      var       - node[26]
      name      - Conv_Conv_20
      operation - convolution
      input     - [32, 32, 64, 1]
      filter    - [1, 1, 64, 24]
      output    - [32, 32, 24, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_CONV2D, 3, 1, 310);
    node[26]->nn_param.conv2d.ksize[0] = 1;
    node[26]->nn_param.conv2d.ksize[1] = 1;
    node[26]->nn_param.conv2d.weights = 24;
    node[26]->nn_param.conv2d.stride[0] = 1;
    node[26]->nn_param.conv2d.stride[1] = 1;
    node[26]->nn_param.conv2d.pad[0] = 0;
    node[26]->nn_param.conv2d.pad[1] = 0;
    node[26]->nn_param.conv2d.pad[2] = 0;
    node[26]->nn_param.conv2d.pad[3] = 0;
    node[26]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[26]->nn_param.conv2d.group = 1;
    node[26]->nn_param.conv2d.dilation[0] = 1;
    node[26]->nn_param.conv2d.dilation[1] = 1;
    node[26]->nn_param.conv2d.multiplier = 0;
    node[26]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[26]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[26]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_22_324
      var       - node[27]
      name      - Conv_Conv_22
      operation - convolution
      input     - [32, 32, 24, 1]
      filter    - [1, 1, 24, 72]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 324);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 72;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_24_320
      var       - node[28]
      name      - Relu_Relu_24
      operation - relu
      input     - [32, 32, 72, 1]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_RELU, 1, 1, 320);

    /*-----------------------------------------
      lid       - Conv_Conv_25_318
      var       - node[29]
      name      - Conv_Conv_25
      operation - convolution
      input     - [32, 32, 72, 1]
      filter    - [3, 3, 72, 1]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV2D, 3, 1, 318);
    node[29]->nn_param.conv2d.ksize[0] = 3;
    node[29]->nn_param.conv2d.ksize[1] = 3;
    node[29]->nn_param.conv2d.weights = 72;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 1;
    node[29]->nn_param.conv2d.pad[1] = 1;
    node[29]->nn_param.conv2d.pad[2] = 1;
    node[29]->nn_param.conv2d.pad[3] = 1;
    node[29]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[29]->nn_param.conv2d.group = 72;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->nn_param.conv2d.multiplier = 1;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_27_316
      var       - node[30]
      name      - Relu_Relu_27
      operation - relu
      input     - [32, 32, 72, 1]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_RELU, 1, 1, 316);

    /*-----------------------------------------
      lid       - Conv_Conv_28_311
      var       - node[31]
      name      - Conv_Conv_28
      operation - convolution
      input     - [32, 32, 72, 1]
      filter    - [1, 1, 72, 24]
      output    - [32, 32, 24, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_CONV2D, 3, 1, 311);
    node[31]->nn_param.conv2d.ksize[0] = 1;
    node[31]->nn_param.conv2d.ksize[1] = 1;
    node[31]->nn_param.conv2d.weights = 24;
    node[31]->nn_param.conv2d.stride[0] = 1;
    node[31]->nn_param.conv2d.stride[1] = 1;
    node[31]->nn_param.conv2d.pad[0] = 0;
    node[31]->nn_param.conv2d.pad[1] = 0;
    node[31]->nn_param.conv2d.pad[2] = 0;
    node[31]->nn_param.conv2d.pad[3] = 0;
    node[31]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[31]->nn_param.conv2d.group = 1;
    node[31]->nn_param.conv2d.dilation[0] = 1;
    node[31]->nn_param.conv2d.dilation[1] = 1;
    node[31]->nn_param.conv2d.multiplier = 0;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_30_300
      var       - node[32]
      name      - Add_Add_30
      operation - add
      input     - [32, 32, 24, 1]
                  [32, 32, 24, 1]
      output    - [32, 32, 24, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_ADD, 2, 1, 300);

    /*-----------------------------------------
      lid       - Conv_Conv_31_294
      var       - node[33]
      name      - Conv_Conv_31
      operation - convolution
      input     - [32, 32, 24, 1]
      filter    - [1, 1, 24, 72]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONV2D, 3, 1, 294);
    node[33]->nn_param.conv2d.ksize[0] = 1;
    node[33]->nn_param.conv2d.ksize[1] = 1;
    node[33]->nn_param.conv2d.weights = 72;
    node[33]->nn_param.conv2d.stride[0] = 1;
    node[33]->nn_param.conv2d.stride[1] = 1;
    node[33]->nn_param.conv2d.pad[0] = 0;
    node[33]->nn_param.conv2d.pad[1] = 0;
    node[33]->nn_param.conv2d.pad[2] = 0;
    node[33]->nn_param.conv2d.pad[3] = 0;
    node[33]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[33]->nn_param.conv2d.group = 1;
    node[33]->nn_param.conv2d.dilation[0] = 1;
    node[33]->nn_param.conv2d.dilation[1] = 1;
    node[33]->nn_param.conv2d.multiplier = 0;
    node[33]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[33]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[33]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_33_279
      var       - node[34]
      name      - Relu_Relu_33
      operation - relu
      input     - [32, 32, 72, 1]
      output    - [32, 32, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_RELU, 1, 1, 279);

    /*-----------------------------------------
      lid       - Conv_Conv_34_273
      var       - node[35]
      name      - Conv_Conv_34
      operation - convolution
      input     - [32, 32, 72, 1]
      filter    - [5, 5, 72, 1]
      output    - [16, 16, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV2D, 3, 1, 273);
    node[35]->nn_param.conv2d.ksize[0] = 5;
    node[35]->nn_param.conv2d.ksize[1] = 5;
    node[35]->nn_param.conv2d.weights = 72;
    node[35]->nn_param.conv2d.stride[0] = 2;
    node[35]->nn_param.conv2d.stride[1] = 2;
    node[35]->nn_param.conv2d.pad[0] = 2;
    node[35]->nn_param.conv2d.pad[1] = 2;
    node[35]->nn_param.conv2d.pad[2] = 2;
    node[35]->nn_param.conv2d.pad[3] = 2;
    node[35]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[35]->nn_param.conv2d.group = 72;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->nn_param.conv2d.multiplier = 1;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_42_312
      var       - node[36]
      name      - GlobalAveragePool_GlobalAveragePool_42
      operation - pooling
      input     - [16, 16, 72, 1]
      output    - [1, 1, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_POOL, 1, 1, 312);
    node[36]->nn_param.pool.ksize[0] = 16;
    node[36]->nn_param.pool.ksize[1] = 16;
    node[36]->nn_param.pool.stride[0] = 1;
    node[36]->nn_param.pool.stride[1] = 1;
    node[36]->nn_param.pool.pad[0] = 0;
    node[36]->nn_param.pool.pad[1] = 0;
    node[36]->nn_param.pool.pad[2] = 0;
    node[36]->nn_param.pool.pad[3] = 0;
    node[36]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[36]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[36]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_46_307
      var       - node[37]
      name      - Reshape_Reshape_46
      operation - reshape
      input     - [1, 1, 72, 1]
      output    - [72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_RESHAPE2, 1, 1, 307);
    node[37]->nn_param.reshape2.size = shape_1;
    node[37]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_47_302
      var       - node[38]
      name      - Gemm_Gemm_47
      operation - fullconnect
      input     - [72, 1]
      filter    - [72, 24]
      output    - [24, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_FCL, 3, 1, 302);
    node[38]->nn_param.fcl.weights = 24;
    node[38]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[38]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[38]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_48_301
      var       - node[39]
      name      - Relu_Relu_48
      operation - relu
      input     - [24, 1]
      output    - [24, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_RELU, 1, 1, 301);

    /*-----------------------------------------
      lid       - Gemm_Gemm_49_295
      var       - node[40]
      name      - Gemm_Gemm_49
      operation - fullconnect
      input     - [24, 1]
      filter    - [24, 72]
      output    - [72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_FCL, 3, 1, 295);
    node[40]->nn_param.fcl.weights = 72;
    node[40]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[40]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[40]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_51_289
      var       - node[41]
      name      - Add_Add_51
      operation - add
      input     - [72, 1]
                  [1, 1]
      output    - [72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_ADD, 2, 1, 289);

    /*-----------------------------------------
      lid       - Clip_Clip_52_280_relun_386
      var       - node[42]
      name      - Clip_Clip_52_280_relun
      operation - relun
      input     - [72, 1]
      output    - [72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_RELUN, 1, 1, 386);
    node[42]->nn_param.relun.relu_clamp_top = 6;
    node[42]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_54_274
      var       - node[43]
      name      - Div_Div_54
      operation - real_div
      input     - [72, 1]
                  [1, 1]
      output    - [72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_DIVIDE, 2, 1, 274);
    node[43]->nn_param.divide.scale = 1;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_58_267
      var       - node[44]
      name      - Reshape_Reshape_58
      operation - reshape
      input     - [72, 1]
      output    - [1, 1, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_RESHAPE2, 1, 1, 267);
    node[44]->nn_param.reshape2.size = shape_2;
    node[44]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_59_262
      var       - node[45]
      name      - Mul_Mul_59
      operation - multiply
      input     - [16, 16, 72, 1]
                  [1, 1, 72, 1]
      output    - [16, 16, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_MULTIPLY, 2, 1, 262);
    node[45]->nn_param.multiply.scale = 1;
    node[45]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[45]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Relu_Relu_60_258
      var       - node[46]
      name      - Relu_Relu_60
      operation - relu
      input     - [16, 16, 72, 1]
      output    - [16, 16, 72, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_RELU, 1, 1, 258);

    /*-----------------------------------------
      lid       - Conv_Conv_61_255
      var       - node[47]
      name      - Conv_Conv_61
      operation - convolution
      input     - [16, 16, 72, 1]
      filter    - [1, 1, 72, 40]
      output    - [16, 16, 40, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_CONV2D, 3, 1, 255);
    node[47]->nn_param.conv2d.ksize[0] = 1;
    node[47]->nn_param.conv2d.ksize[1] = 1;
    node[47]->nn_param.conv2d.weights = 40;
    node[47]->nn_param.conv2d.stride[0] = 1;
    node[47]->nn_param.conv2d.stride[1] = 1;
    node[47]->nn_param.conv2d.pad[0] = 0;
    node[47]->nn_param.conv2d.pad[1] = 0;
    node[47]->nn_param.conv2d.pad[2] = 0;
    node[47]->nn_param.conv2d.pad[3] = 0;
    node[47]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[47]->nn_param.conv2d.group = 1;
    node[47]->nn_param.conv2d.dilation[0] = 1;
    node[47]->nn_param.conv2d.dilation[1] = 1;
    node[47]->nn_param.conv2d.multiplier = 0;
    node[47]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[47]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[47]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_63_297
      var       - node[48]
      name      - Conv_Conv_63
      operation - convolution
      input     - [16, 16, 40, 1]
      filter    - [1, 1, 40, 120]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV2D, 3, 1, 297);
    node[48]->nn_param.conv2d.ksize[0] = 1;
    node[48]->nn_param.conv2d.ksize[1] = 1;
    node[48]->nn_param.conv2d.weights = 120;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 0;
    node[48]->nn_param.conv2d.pad[1] = 0;
    node[48]->nn_param.conv2d.pad[2] = 0;
    node[48]->nn_param.conv2d.pad[3] = 0;
    node[48]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->nn_param.conv2d.multiplier = 0;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_65_282
      var       - node[49]
      name      - Relu_Relu_65
      operation - relu
      input     - [16, 16, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_RELU, 1, 1, 282);

    /*-----------------------------------------
      lid       - Conv_Conv_66_275
      var       - node[50]
      name      - Conv_Conv_66
      operation - convolution
      input     - [16, 16, 120, 1]
      filter    - [5, 5, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_CONV2D, 3, 1, 275);
    node[50]->nn_param.conv2d.ksize[0] = 5;
    node[50]->nn_param.conv2d.ksize[1] = 5;
    node[50]->nn_param.conv2d.weights = 120;
    node[50]->nn_param.conv2d.stride[0] = 1;
    node[50]->nn_param.conv2d.stride[1] = 1;
    node[50]->nn_param.conv2d.pad[0] = 2;
    node[50]->nn_param.conv2d.pad[1] = 2;
    node[50]->nn_param.conv2d.pad[2] = 2;
    node[50]->nn_param.conv2d.pad[3] = 2;
    node[50]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[50]->nn_param.conv2d.group = 120;
    node[50]->nn_param.conv2d.dilation[0] = 1;
    node[50]->nn_param.conv2d.dilation[1] = 1;
    node[50]->nn_param.conv2d.multiplier = 1;
    node[50]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[50]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[50]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_74_314
      var       - node[51]
      name      - GlobalAveragePool_GlobalAveragePool_74
      operation - pooling
      input     - [16, 16, 120, 1]
      output    - [1, 1, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_POOL, 1, 1, 314);
    node[51]->nn_param.pool.ksize[0] = 16;
    node[51]->nn_param.pool.ksize[1] = 16;
    node[51]->nn_param.pool.stride[0] = 1;
    node[51]->nn_param.pool.stride[1] = 1;
    node[51]->nn_param.pool.pad[0] = 0;
    node[51]->nn_param.pool.pad[1] = 0;
    node[51]->nn_param.pool.pad[2] = 0;
    node[51]->nn_param.pool.pad[3] = 0;
    node[51]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[51]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[51]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_78_313
      var       - node[52]
      name      - Reshape_Reshape_78
      operation - reshape
      input     - [1, 1, 120, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_RESHAPE2, 1, 1, 313);
    node[52]->nn_param.reshape2.size = shape_3;
    node[52]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_79_308
      var       - node[53]
      name      - Gemm_Gemm_79
      operation - fullconnect
      input     - [120, 1]
      filter    - [120, 32]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_FCL, 3, 1, 308);
    node[53]->nn_param.fcl.weights = 32;
    node[53]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[53]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[53]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_80_303
      var       - node[54]
      name      - Relu_Relu_80
      operation - relu
      input     - [32, 1]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_RELU, 1, 1, 303);

    /*-----------------------------------------
      lid       - Gemm_Gemm_81_298
      var       - node[55]
      name      - Gemm_Gemm_81
      operation - fullconnect
      input     - [32, 1]
      filter    - [32, 120]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_FCL, 3, 1, 298);
    node[55]->nn_param.fcl.weights = 120;
    node[55]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[55]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[55]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_83_291
      var       - node[56]
      name      - Add_Add_83
      operation - add
      input     - [120, 1]
                  [1, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_ADD, 2, 1, 291);

    /*-----------------------------------------
      lid       - Clip_Clip_84_283_relun_387
      var       - node[57]
      name      - Clip_Clip_84_283_relun
      operation - relun
      input     - [120, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_RELUN, 1, 1, 387);
    node[57]->nn_param.relun.relu_clamp_top = 6;
    node[57]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_86_276
      var       - node[58]
      name      - Div_Div_86
      operation - real_div
      input     - [120, 1]
                  [1, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_DIVIDE, 2, 1, 276);
    node[58]->nn_param.divide.scale = 1;
    node[58]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[58]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_90_269
      var       - node[59]
      name      - Reshape_Reshape_90
      operation - reshape
      input     - [120, 1]
      output    - [1, 1, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_RESHAPE2, 1, 1, 269);
    node[59]->nn_param.reshape2.size = shape_4;
    node[59]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_91_263
      var       - node[60]
      name      - Mul_Mul_91
      operation - multiply
      input     - [16, 16, 120, 1]
                  [1, 1, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_MULTIPLY, 2, 1, 263);
    node[60]->nn_param.multiply.scale = 1;
    node[60]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[60]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Relu_Relu_92_259
      var       - node[61]
      name      - Relu_Relu_92
      operation - relu
      input     - [16, 16, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_RELU, 1, 1, 259);

    /*-----------------------------------------
      lid       - Conv_Conv_93_256
      var       - node[62]
      name      - Conv_Conv_93
      operation - convolution
      input     - [16, 16, 120, 1]
      filter    - [1, 1, 120, 40]
      output    - [16, 16, 40, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV2D, 3, 1, 256);
    node[62]->nn_param.conv2d.ksize[0] = 1;
    node[62]->nn_param.conv2d.ksize[1] = 1;
    node[62]->nn_param.conv2d.weights = 40;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 0;
    node[62]->nn_param.conv2d.pad[1] = 0;
    node[62]->nn_param.conv2d.pad[2] = 0;
    node[62]->nn_param.conv2d.pad[3] = 0;
    node[62]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->nn_param.conv2d.multiplier = 0;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_95_250
      var       - node[63]
      name      - Add_Add_95
      operation - add
      input     - [16, 16, 40, 1]
                  [16, 16, 40, 1]
      output    - [16, 16, 40, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_ADD, 2, 1, 250);

    /*-----------------------------------------
      lid       - Conv_Conv_96_285
      var       - node[64]
      name      - Conv_Conv_96
      operation - convolution
      input     - [16, 16, 40, 1]
      filter    - [1, 1, 40, 120]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_CONV2D, 3, 1, 285);
    node[64]->nn_param.conv2d.ksize[0] = 1;
    node[64]->nn_param.conv2d.ksize[1] = 1;
    node[64]->nn_param.conv2d.weights = 120;
    node[64]->nn_param.conv2d.stride[0] = 1;
    node[64]->nn_param.conv2d.stride[1] = 1;
    node[64]->nn_param.conv2d.pad[0] = 0;
    node[64]->nn_param.conv2d.pad[1] = 0;
    node[64]->nn_param.conv2d.pad[2] = 0;
    node[64]->nn_param.conv2d.pad[3] = 0;
    node[64]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[64]->nn_param.conv2d.group = 1;
    node[64]->nn_param.conv2d.dilation[0] = 1;
    node[64]->nn_param.conv2d.dilation[1] = 1;
    node[64]->nn_param.conv2d.multiplier = 0;
    node[64]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[64]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[64]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_98_270
      var       - node[65]
      name      - Relu_Relu_98
      operation - relu
      input     - [16, 16, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_RELU, 1, 1, 270);

    /*-----------------------------------------
      lid       - Conv_Conv_99_264
      var       - node[66]
      name      - Conv_Conv_99
      operation - convolution
      input     - [16, 16, 120, 1]
      filter    - [5, 5, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_CONV2D, 3, 1, 264);
    node[66]->nn_param.conv2d.ksize[0] = 5;
    node[66]->nn_param.conv2d.ksize[1] = 5;
    node[66]->nn_param.conv2d.weights = 120;
    node[66]->nn_param.conv2d.stride[0] = 1;
    node[66]->nn_param.conv2d.stride[1] = 1;
    node[66]->nn_param.conv2d.pad[0] = 2;
    node[66]->nn_param.conv2d.pad[1] = 2;
    node[66]->nn_param.conv2d.pad[2] = 2;
    node[66]->nn_param.conv2d.pad[3] = 2;
    node[66]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[66]->nn_param.conv2d.group = 120;
    node[66]->nn_param.conv2d.dilation[0] = 1;
    node[66]->nn_param.conv2d.dilation[1] = 1;
    node[66]->nn_param.conv2d.multiplier = 1;
    node[66]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[66]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[66]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_107_309
      var       - node[67]
      name      - GlobalAveragePool_GlobalAveragePool_107
      operation - pooling
      input     - [16, 16, 120, 1]
      output    - [1, 1, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_POOL, 1, 1, 309);
    node[67]->nn_param.pool.ksize[0] = 16;
    node[67]->nn_param.pool.ksize[1] = 16;
    node[67]->nn_param.pool.stride[0] = 1;
    node[67]->nn_param.pool.stride[1] = 1;
    node[67]->nn_param.pool.pad[0] = 0;
    node[67]->nn_param.pool.pad[1] = 0;
    node[67]->nn_param.pool.pad[2] = 0;
    node[67]->nn_param.pool.pad[3] = 0;
    node[67]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[67]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[67]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_111_304
      var       - node[68]
      name      - Reshape_Reshape_111
      operation - reshape
      input     - [1, 1, 120, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_RESHAPE2, 1, 1, 304);
    node[68]->nn_param.reshape2.size = shape_5;
    node[68]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_112_299
      var       - node[69]
      name      - Gemm_Gemm_112
      operation - fullconnect
      input     - [120, 1]
      filter    - [120, 32]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_FCL, 3, 1, 299);
    node[69]->nn_param.fcl.weights = 32;
    node[69]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[69]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[69]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_113_293
      var       - node[70]
      name      - Relu_Relu_113
      operation - relu
      input     - [32, 1]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_RELU, 1, 1, 293);

    /*-----------------------------------------
      lid       - Gemm_Gemm_114_286
      var       - node[71]
      name      - Gemm_Gemm_114
      operation - fullconnect
      input     - [32, 1]
      filter    - [32, 120]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_FCL, 3, 1, 286);
    node[71]->nn_param.fcl.weights = 120;
    node[71]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[71]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[71]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_116_278
      var       - node[72]
      name      - Add_Add_116
      operation - add
      input     - [120, 1]
                  [1, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_ADD, 2, 1, 278);

    /*-----------------------------------------
      lid       - Clip_Clip_117_271_relun_385
      var       - node[73]
      name      - Clip_Clip_117_271_relun
      operation - relun
      input     - [120, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_RELUN, 1, 1, 385);
    node[73]->nn_param.relun.relu_clamp_top = 6;
    node[73]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_119_265
      var       - node[74]
      name      - Div_Div_119
      operation - real_div
      input     - [120, 1]
                  [1, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_DIVIDE, 2, 1, 265);
    node[74]->nn_param.divide.scale = 1;
    node[74]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[74]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_123_261
      var       - node[75]
      name      - Reshape_Reshape_123
      operation - reshape
      input     - [120, 1]
      output    - [1, 1, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_RESHAPE2, 1, 1, 261);
    node[75]->nn_param.reshape2.size = shape_6;
    node[75]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_124_257
      var       - node[76]
      name      - Mul_Mul_124
      operation - multiply
      input     - [16, 16, 120, 1]
                  [1, 1, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_MULTIPLY, 2, 1, 257);
    node[76]->nn_param.multiply.scale = 1;
    node[76]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[76]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Relu_Relu_125_254
      var       - node[77]
      name      - Relu_Relu_125
      operation - relu
      input     - [16, 16, 120, 1]
      output    - [16, 16, 120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_RELU, 1, 1, 254);

    /*-----------------------------------------
      lid       - Conv_Conv_126_251
      var       - node[78]
      name      - Conv_Conv_126
      operation - convolution
      input     - [16, 16, 120, 1]
      filter    - [1, 1, 120, 40]
      output    - [16, 16, 40, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONV2D, 3, 1, 251);
    node[78]->nn_param.conv2d.ksize[0] = 1;
    node[78]->nn_param.conv2d.ksize[1] = 1;
    node[78]->nn_param.conv2d.weights = 40;
    node[78]->nn_param.conv2d.stride[0] = 1;
    node[78]->nn_param.conv2d.stride[1] = 1;
    node[78]->nn_param.conv2d.pad[0] = 0;
    node[78]->nn_param.conv2d.pad[1] = 0;
    node[78]->nn_param.conv2d.pad[2] = 0;
    node[78]->nn_param.conv2d.pad[3] = 0;
    node[78]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[78]->nn_param.conv2d.group = 1;
    node[78]->nn_param.conv2d.dilation[0] = 1;
    node[78]->nn_param.conv2d.dilation[1] = 1;
    node[78]->nn_param.conv2d.multiplier = 0;
    node[78]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[78]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[78]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_128_246
      var       - node[79]
      name      - Add_Add_128
      operation - add
      input     - [16, 16, 40, 1]
                  [16, 16, 40, 1]
      output    - [16, 16, 40, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_ADD, 2, 1, 246);

    /*-----------------------------------------
      lid       - Conv_Conv_129_239
      var       - node[80]
      name      - Conv_Conv_129
      operation - convolution
      input     - [16, 16, 40, 1]
      filter    - [1, 1, 40, 240]
      output    - [16, 16, 240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_CONV2D, 3, 1, 239);
    node[80]->nn_param.conv2d.ksize[0] = 1;
    node[80]->nn_param.conv2d.ksize[1] = 1;
    node[80]->nn_param.conv2d.weights = 240;
    node[80]->nn_param.conv2d.stride[0] = 1;
    node[80]->nn_param.conv2d.stride[1] = 1;
    node[80]->nn_param.conv2d.pad[0] = 0;
    node[80]->nn_param.conv2d.pad[1] = 0;
    node[80]->nn_param.conv2d.pad[2] = 0;
    node[80]->nn_param.conv2d.pad[3] = 0;
    node[80]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[80]->nn_param.conv2d.group = 1;
    node[80]->nn_param.conv2d.dilation[0] = 1;
    node[80]->nn_param.conv2d.dilation[1] = 1;
    node[80]->nn_param.conv2d.multiplier = 0;
    node[80]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[80]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[80]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_132_247_Clip_Clip_133_240_relun_383_Div_Div_135_230_Mul_Mul_136_220
      var       - node[81]
      name      - hard_swish
      operation - hard_swish
      input     - [16, 16, 240, 1]
      output    - [16, 16, 240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_SWISH, 1, 1, 220);
    node[81]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_137_210
      var       - node[82]
      name      - Conv_Conv_137
      operation - convolution
      input     - [16, 16, 240, 1]
      filter    - [3, 3, 240, 1]
      output    - [8, 8, 240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_CONV2D, 3, 1, 210);
    node[82]->nn_param.conv2d.ksize[0] = 3;
    node[82]->nn_param.conv2d.ksize[1] = 3;
    node[82]->nn_param.conv2d.weights = 240;
    node[82]->nn_param.conv2d.stride[0] = 2;
    node[82]->nn_param.conv2d.stride[1] = 2;
    node[82]->nn_param.conv2d.pad[0] = 1;
    node[82]->nn_param.conv2d.pad[1] = 1;
    node[82]->nn_param.conv2d.pad[2] = 1;
    node[82]->nn_param.conv2d.pad[3] = 1;
    node[82]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[82]->nn_param.conv2d.group = 240;
    node[82]->nn_param.conv2d.dilation[0] = 1;
    node[82]->nn_param.conv2d.dilation[1] = 1;
    node[82]->nn_param.conv2d.multiplier = 1;
    node[82]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[82]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[82]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_140_221_Clip_Clip_141_211_relun_380_Div_Div_143_202_Mul_Mul_144_193
      var       - node[83]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 240, 1]
      output    - [8, 8, 240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_SWISH, 1, 1, 193);
    node[83]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_145_188
      var       - node[84]
      name      - Conv_Conv_145
      operation - convolution
      input     - [8, 8, 240, 1]
      filter    - [1, 1, 240, 80]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_CONV2D, 3, 1, 188);
    node[84]->nn_param.conv2d.ksize[0] = 1;
    node[84]->nn_param.conv2d.ksize[1] = 1;
    node[84]->nn_param.conv2d.weights = 80;
    node[84]->nn_param.conv2d.stride[0] = 1;
    node[84]->nn_param.conv2d.stride[1] = 1;
    node[84]->nn_param.conv2d.pad[0] = 0;
    node[84]->nn_param.conv2d.pad[1] = 0;
    node[84]->nn_param.conv2d.pad[2] = 0;
    node[84]->nn_param.conv2d.pad[3] = 0;
    node[84]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[84]->nn_param.conv2d.group = 1;
    node[84]->nn_param.conv2d.dilation[0] = 1;
    node[84]->nn_param.conv2d.dilation[1] = 1;
    node[84]->nn_param.conv2d.multiplier = 0;
    node[84]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[84]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[84]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_147_241
      var       - node[85]
      name      - Conv_Conv_147
      operation - convolution
      input     - [8, 8, 80, 1]
      filter    - [1, 1, 80, 200]
      output    - [8, 8, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV2D, 3, 1, 241);
    node[85]->nn_param.conv2d.ksize[0] = 1;
    node[85]->nn_param.conv2d.ksize[1] = 1;
    node[85]->nn_param.conv2d.weights = 200;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 0;
    node[85]->nn_param.conv2d.pad[1] = 0;
    node[85]->nn_param.conv2d.pad[2] = 0;
    node[85]->nn_param.conv2d.pad[3] = 0;
    node[85]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->nn_param.conv2d.multiplier = 0;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_150_243_Clip_Clip_151_242_relun_384_Div_Div_153_234_Mul_Mul_154_222
      var       - node[86]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 200, 1]
      output    - [8, 8, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_SWISH, 1, 1, 222);
    node[86]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_155_213
      var       - node[87]
      name      - Conv_Conv_155
      operation - convolution
      input     - [8, 8, 200, 1]
      filter    - [3, 3, 200, 1]
      output    - [8, 8, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_CONV2D, 3, 1, 213);
    node[87]->nn_param.conv2d.ksize[0] = 3;
    node[87]->nn_param.conv2d.ksize[1] = 3;
    node[87]->nn_param.conv2d.weights = 200;
    node[87]->nn_param.conv2d.stride[0] = 1;
    node[87]->nn_param.conv2d.stride[1] = 1;
    node[87]->nn_param.conv2d.pad[0] = 1;
    node[87]->nn_param.conv2d.pad[1] = 1;
    node[87]->nn_param.conv2d.pad[2] = 1;
    node[87]->nn_param.conv2d.pad[3] = 1;
    node[87]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[87]->nn_param.conv2d.group = 200;
    node[87]->nn_param.conv2d.dilation[0] = 1;
    node[87]->nn_param.conv2d.dilation[1] = 1;
    node[87]->nn_param.conv2d.multiplier = 1;
    node[87]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[87]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[87]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_158_223_Clip_Clip_159_214_relun_381_Div_Div_161_204_Mul_Mul_162_194
      var       - node[88]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 200, 1]
      output    - [8, 8, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_SWISH, 1, 1, 194);
    node[88]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_163_189
      var       - node[89]
      name      - Conv_Conv_163
      operation - convolution
      input     - [8, 8, 200, 1]
      filter    - [1, 1, 200, 80]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_CONV2D, 3, 1, 189);
    node[89]->nn_param.conv2d.ksize[0] = 1;
    node[89]->nn_param.conv2d.ksize[1] = 1;
    node[89]->nn_param.conv2d.weights = 80;
    node[89]->nn_param.conv2d.stride[0] = 1;
    node[89]->nn_param.conv2d.stride[1] = 1;
    node[89]->nn_param.conv2d.pad[0] = 0;
    node[89]->nn_param.conv2d.pad[1] = 0;
    node[89]->nn_param.conv2d.pad[2] = 0;
    node[89]->nn_param.conv2d.pad[3] = 0;
    node[89]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[89]->nn_param.conv2d.group = 1;
    node[89]->nn_param.conv2d.dilation[0] = 1;
    node[89]->nn_param.conv2d.dilation[1] = 1;
    node[89]->nn_param.conv2d.multiplier = 0;
    node[89]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[89]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[89]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_165_178
      var       - node[90]
      name      - Add_Add_165
      operation - add
      input     - [8, 8, 80, 1]
                  [8, 8, 80, 1]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_ADD, 2, 1, 178);

    /*-----------------------------------------
      lid       - Conv_Conv_166_237
      var       - node[91]
      name      - Conv_Conv_166
      operation - convolution
      input     - [8, 8, 80, 1]
      filter    - [1, 1, 80, 184]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV2D, 3, 1, 237);
    node[91]->nn_param.conv2d.ksize[0] = 1;
    node[91]->nn_param.conv2d.ksize[1] = 1;
    node[91]->nn_param.conv2d.weights = 184;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 0;
    node[91]->nn_param.conv2d.pad[1] = 0;
    node[91]->nn_param.conv2d.pad[2] = 0;
    node[91]->nn_param.conv2d.pad[3] = 0;
    node[91]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->nn_param.conv2d.multiplier = 0;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_169_238_Clip_Clip_170_227_relun_382_Div_Div_172_225_Mul_Mul_173_216
      var       - node[92]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_SWISH, 1, 1, 216);
    node[92]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_174_205
      var       - node[93]
      name      - Conv_Conv_174
      operation - convolution
      input     - [8, 8, 184, 1]
      filter    - [3, 3, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONV2D, 3, 1, 205);
    node[93]->nn_param.conv2d.ksize[0] = 3;
    node[93]->nn_param.conv2d.ksize[1] = 3;
    node[93]->nn_param.conv2d.weights = 184;
    node[93]->nn_param.conv2d.stride[0] = 1;
    node[93]->nn_param.conv2d.stride[1] = 1;
    node[93]->nn_param.conv2d.pad[0] = 1;
    node[93]->nn_param.conv2d.pad[1] = 1;
    node[93]->nn_param.conv2d.pad[2] = 1;
    node[93]->nn_param.conv2d.pad[3] = 1;
    node[93]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[93]->nn_param.conv2d.group = 184;
    node[93]->nn_param.conv2d.dilation[0] = 1;
    node[93]->nn_param.conv2d.dilation[1] = 1;
    node[93]->nn_param.conv2d.multiplier = 1;
    node[93]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[93]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[93]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_177_217_Clip_Clip_178_206_relun_378_Div_Div_180_196_Mul_Mul_181_190
      var       - node[94]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_SWISH, 1, 1, 190);
    node[94]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_182_185
      var       - node[95]
      name      - Conv_Conv_182
      operation - convolution
      input     - [8, 8, 184, 1]
      filter    - [1, 1, 184, 80]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_CONV2D, 3, 1, 185);
    node[95]->nn_param.conv2d.ksize[0] = 1;
    node[95]->nn_param.conv2d.ksize[1] = 1;
    node[95]->nn_param.conv2d.weights = 80;
    node[95]->nn_param.conv2d.stride[0] = 1;
    node[95]->nn_param.conv2d.stride[1] = 1;
    node[95]->nn_param.conv2d.pad[0] = 0;
    node[95]->nn_param.conv2d.pad[1] = 0;
    node[95]->nn_param.conv2d.pad[2] = 0;
    node[95]->nn_param.conv2d.pad[3] = 0;
    node[95]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[95]->nn_param.conv2d.group = 1;
    node[95]->nn_param.conv2d.dilation[0] = 1;
    node[95]->nn_param.conv2d.dilation[1] = 1;
    node[95]->nn_param.conv2d.multiplier = 0;
    node[95]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[95]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[95]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_184_172
      var       - node[96]
      name      - Add_Add_184
      operation - add
      input     - [8, 8, 80, 1]
                  [8, 8, 80, 1]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_ADD, 2, 1, 172);

    /*-----------------------------------------
      lid       - Conv_Conv_185_208
      var       - node[97]
      name      - Conv_Conv_185
      operation - convolution
      input     - [8, 8, 80, 1]
      filter    - [1, 1, 80, 184]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_CONV2D, 3, 1, 208);
    node[97]->nn_param.conv2d.ksize[0] = 1;
    node[97]->nn_param.conv2d.ksize[1] = 1;
    node[97]->nn_param.conv2d.weights = 184;
    node[97]->nn_param.conv2d.stride[0] = 1;
    node[97]->nn_param.conv2d.stride[1] = 1;
    node[97]->nn_param.conv2d.pad[0] = 0;
    node[97]->nn_param.conv2d.pad[1] = 0;
    node[97]->nn_param.conv2d.pad[2] = 0;
    node[97]->nn_param.conv2d.pad[3] = 0;
    node[97]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[97]->nn_param.conv2d.group = 1;
    node[97]->nn_param.conv2d.dilation[0] = 1;
    node[97]->nn_param.conv2d.dilation[1] = 1;
    node[97]->nn_param.conv2d.multiplier = 0;
    node[97]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[97]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[97]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_188_219_Clip_Clip_189_209_relun_379_Div_Div_191_198_Mul_Mul_192_191
      var       - node[98]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_SWISH, 1, 1, 191);
    node[98]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_193_186
      var       - node[99]
      name      - Conv_Conv_193
      operation - convolution
      input     - [8, 8, 184, 1]
      filter    - [3, 3, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONV2D, 3, 1, 186);
    node[99]->nn_param.conv2d.ksize[0] = 3;
    node[99]->nn_param.conv2d.ksize[1] = 3;
    node[99]->nn_param.conv2d.weights = 184;
    node[99]->nn_param.conv2d.stride[0] = 1;
    node[99]->nn_param.conv2d.stride[1] = 1;
    node[99]->nn_param.conv2d.pad[0] = 1;
    node[99]->nn_param.conv2d.pad[1] = 1;
    node[99]->nn_param.conv2d.pad[2] = 1;
    node[99]->nn_param.conv2d.pad[3] = 1;
    node[99]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[99]->nn_param.conv2d.group = 184;
    node[99]->nn_param.conv2d.dilation[0] = 1;
    node[99]->nn_param.conv2d.dilation[1] = 1;
    node[99]->nn_param.conv2d.multiplier = 1;
    node[99]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[99]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[99]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_196_192_Clip_Clip_197_187_relun_377_Div_Div_199_181_Mul_Mul_200_176
      var       - node[100]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 184, 1]
      output    - [8, 8, 184, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_SWISH, 1, 1, 176);
    node[100]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_201_174
      var       - node[101]
      name      - Conv_Conv_201
      operation - convolution
      input     - [8, 8, 184, 1]
      filter    - [1, 1, 184, 80]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV2D, 3, 1, 174);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 1;
    node[101]->nn_param.conv2d.weights = 80;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 0;
    node[101]->nn_param.conv2d.pad[3] = 0;
    node[101]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->nn_param.conv2d.multiplier = 0;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_203_168
      var       - node[102]
      name      - Add_Add_203
      operation - add
      input     - [8, 8, 80, 1]
                  [8, 8, 80, 1]
      output    - [8, 8, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_ADD, 2, 1, 168);

    /*-----------------------------------------
      lid       - Conv_Conv_204_161
      var       - node[103]
      name      - Conv_Conv_204
      operation - convolution
      input     - [8, 8, 80, 1]
      filter    - [1, 1, 80, 480]
      output    - [8, 8, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_CONV2D, 3, 1, 161);
    node[103]->nn_param.conv2d.ksize[0] = 1;
    node[103]->nn_param.conv2d.ksize[1] = 1;
    node[103]->nn_param.conv2d.weights = 480;
    node[103]->nn_param.conv2d.stride[0] = 1;
    node[103]->nn_param.conv2d.stride[1] = 1;
    node[103]->nn_param.conv2d.pad[0] = 0;
    node[103]->nn_param.conv2d.pad[1] = 0;
    node[103]->nn_param.conv2d.pad[2] = 0;
    node[103]->nn_param.conv2d.pad[3] = 0;
    node[103]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[103]->nn_param.conv2d.group = 1;
    node[103]->nn_param.conv2d.dilation[0] = 1;
    node[103]->nn_param.conv2d.dilation[1] = 1;
    node[103]->nn_param.conv2d.multiplier = 0;
    node[103]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[103]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[103]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_207_169_Clip_Clip_208_162_relun_376_Div_Div_210_155_Mul_Mul_211_144
      var       - node[104]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 480, 1]
      output    - [8, 8, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_SWISH, 1, 1, 144);
    node[104]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_212_138
      var       - node[105]
      name      - Conv_Conv_212
      operation - convolution
      input     - [8, 8, 480, 1]
      filter    - [3, 3, 480, 1]
      output    - [8, 8, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_CONV2D, 3, 1, 138);
    node[105]->nn_param.conv2d.ksize[0] = 3;
    node[105]->nn_param.conv2d.ksize[1] = 3;
    node[105]->nn_param.conv2d.weights = 480;
    node[105]->nn_param.conv2d.stride[0] = 1;
    node[105]->nn_param.conv2d.stride[1] = 1;
    node[105]->nn_param.conv2d.pad[0] = 1;
    node[105]->nn_param.conv2d.pad[1] = 1;
    node[105]->nn_param.conv2d.pad[2] = 1;
    node[105]->nn_param.conv2d.pad[3] = 1;
    node[105]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[105]->nn_param.conv2d.group = 480;
    node[105]->nn_param.conv2d.dilation[0] = 1;
    node[105]->nn_param.conv2d.dilation[1] = 1;
    node[105]->nn_param.conv2d.multiplier = 1;
    node[105]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[105]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[105]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_220_170
      var       - node[106]
      name      - GlobalAveragePool_GlobalAveragePool_220
      operation - pooling
      input     - [8, 8, 480, 1]
      output    - [1, 1, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_POOL, 1, 1, 170);
    node[106]->nn_param.pool.ksize[0] = 8;
    node[106]->nn_param.pool.ksize[1] = 8;
    node[106]->nn_param.pool.stride[0] = 1;
    node[106]->nn_param.pool.stride[1] = 1;
    node[106]->nn_param.pool.pad[0] = 0;
    node[106]->nn_param.pool.pad[1] = 0;
    node[106]->nn_param.pool.pad[2] = 0;
    node[106]->nn_param.pool.pad[3] = 0;
    node[106]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[106]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_224_165
      var       - node[107]
      name      - Reshape_Reshape_224
      operation - reshape
      input     - [1, 1, 480, 1]
      output    - [480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_RESHAPE2, 1, 1, 165);
    node[107]->nn_param.reshape2.size = shape_7;
    node[107]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_225_164
      var       - node[108]
      name      - Gemm_Gemm_225
      operation - fullconnect
      input     - [480, 1]
      filter    - [480, 120]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_FCL, 3, 1, 164);
    node[108]->nn_param.fcl.weights = 120;
    node[108]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[108]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[108]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_226_158
      var       - node[109]
      name      - Relu_Relu_226
      operation - relu
      input     - [120, 1]
      output    - [120, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_RELU, 1, 1, 158);

    /*-----------------------------------------
      lid       - Gemm_Gemm_227_156
      var       - node[110]
      name      - Gemm_Gemm_227
      operation - fullconnect
      input     - [120, 1]
      filter    - [120, 480]
      output    - [480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_FCL, 3, 1, 156);
    node[110]->nn_param.fcl.weights = 480;
    node[110]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[110]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[110]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_229_147
      var       - node[111]
      name      - Add_Add_229
      operation - add
      input     - [480, 1]
                  [1, 1]
      output    - [480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_ADD, 2, 1, 147);

    /*-----------------------------------------
      lid       - Clip_Clip_230_145_relun_374
      var       - node[112]
      name      - Clip_Clip_230_145_relun
      operation - relun
      input     - [480, 1]
      output    - [480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_RELUN, 1, 1, 374);
    node[112]->nn_param.relun.relu_clamp_top = 6;
    node[112]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_232_139
      var       - node[113]
      name      - Div_Div_232
      operation - real_div
      input     - [480, 1]
                  [1, 1]
      output    - [480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_DIVIDE, 2, 1, 139);
    node[113]->nn_param.divide.scale = 1;
    node[113]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[113]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_236_133
      var       - node[114]
      name      - Reshape_Reshape_236
      operation - reshape
      input     - [480, 1]
      output    - [1, 1, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_RESHAPE2, 1, 1, 133);
    node[114]->nn_param.reshape2.size = shape_8;
    node[114]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_237_126
      var       - node[115]
      name      - Mul_Mul_237
      operation - multiply
      input     - [8, 8, 480, 1]
                  [1, 1, 480, 1]
      output    - [8, 8, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_MULTIPLY, 2, 1, 126);
    node[115]->nn_param.multiply.scale = 1;
    node[115]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[115]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Add_Add_239_140_Clip_Clip_240_134_relun_372_Div_Div_242_127_Mul_Mul_243_122
      var       - node[116]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 480, 1]
      output    - [8, 8, 480, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_SWISH, 1, 1, 122);
    node[116]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_244_119
      var       - node[117]
      name      - Conv_Conv_244
      operation - convolution
      input     - [8, 8, 480, 1]
      filter    - [1, 1, 480, 112]
      output    - [8, 8, 112, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_CONV2D, 3, 1, 119);
    node[117]->nn_param.conv2d.ksize[0] = 1;
    node[117]->nn_param.conv2d.ksize[1] = 1;
    node[117]->nn_param.conv2d.weights = 112;
    node[117]->nn_param.conv2d.stride[0] = 1;
    node[117]->nn_param.conv2d.stride[1] = 1;
    node[117]->nn_param.conv2d.pad[0] = 0;
    node[117]->nn_param.conv2d.pad[1] = 0;
    node[117]->nn_param.conv2d.pad[2] = 0;
    node[117]->nn_param.conv2d.pad[3] = 0;
    node[117]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[117]->nn_param.conv2d.group = 1;
    node[117]->nn_param.conv2d.dilation[0] = 1;
    node[117]->nn_param.conv2d.dilation[1] = 1;
    node[117]->nn_param.conv2d.multiplier = 0;
    node[117]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[117]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[117]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_246_149
      var       - node[118]
      name      - Conv_Conv_246
      operation - convolution
      input     - [8, 8, 112, 1]
      filter    - [1, 1, 112, 672]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_CONV2D, 3, 1, 149);
    node[118]->nn_param.conv2d.ksize[0] = 1;
    node[118]->nn_param.conv2d.ksize[1] = 1;
    node[118]->nn_param.conv2d.weights = 672;
    node[118]->nn_param.conv2d.stride[0] = 1;
    node[118]->nn_param.conv2d.stride[1] = 1;
    node[118]->nn_param.conv2d.pad[0] = 0;
    node[118]->nn_param.conv2d.pad[1] = 0;
    node[118]->nn_param.conv2d.pad[2] = 0;
    node[118]->nn_param.conv2d.pad[3] = 0;
    node[118]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[118]->nn_param.conv2d.group = 1;
    node[118]->nn_param.conv2d.dilation[0] = 1;
    node[118]->nn_param.conv2d.dilation[1] = 1;
    node[118]->nn_param.conv2d.multiplier = 0;
    node[118]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[118]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[118]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_249_159_Clip_Clip_250_150_relun_375_Div_Div_252_142_Mul_Mul_253_136
      var       - node[119]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 672, 1]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_SWISH, 1, 1, 136);
    node[119]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_254_128
      var       - node[120]
      name      - Conv_Conv_254
      operation - convolution
      input     - [8, 8, 672, 1]
      filter    - [3, 3, 672, 1]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_CONV2D, 3, 1, 128);
    node[120]->nn_param.conv2d.ksize[0] = 3;
    node[120]->nn_param.conv2d.ksize[1] = 3;
    node[120]->nn_param.conv2d.weights = 672;
    node[120]->nn_param.conv2d.stride[0] = 1;
    node[120]->nn_param.conv2d.stride[1] = 1;
    node[120]->nn_param.conv2d.pad[0] = 1;
    node[120]->nn_param.conv2d.pad[1] = 1;
    node[120]->nn_param.conv2d.pad[2] = 1;
    node[120]->nn_param.conv2d.pad[3] = 1;
    node[120]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[120]->nn_param.conv2d.group = 672;
    node[120]->nn_param.conv2d.dilation[0] = 1;
    node[120]->nn_param.conv2d.dilation[1] = 1;
    node[120]->nn_param.conv2d.multiplier = 1;
    node[120]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[120]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[120]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_262_177
      var       - node[121]
      name      - GlobalAveragePool_GlobalAveragePool_262
      operation - pooling
      input     - [8, 8, 672, 1]
      output    - [1, 1, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_POOL, 1, 1, 177);
    node[121]->nn_param.pool.ksize[0] = 8;
    node[121]->nn_param.pool.ksize[1] = 8;
    node[121]->nn_param.pool.stride[0] = 1;
    node[121]->nn_param.pool.stride[1] = 1;
    node[121]->nn_param.pool.pad[0] = 0;
    node[121]->nn_param.pool.pad[1] = 0;
    node[121]->nn_param.pool.pad[2] = 0;
    node[121]->nn_param.pool.pad[3] = 0;
    node[121]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[121]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[121]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_266_171
      var       - node[122]
      name      - Reshape_Reshape_266
      operation - reshape
      input     - [1, 1, 672, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_RESHAPE2, 1, 1, 171);
    node[122]->nn_param.reshape2.size = shape_9;
    node[122]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_267_167
      var       - node[123]
      name      - Gemm_Gemm_267
      operation - fullconnect
      input     - [672, 1]
      filter    - [672, 168]
      output    - [168, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_FCL, 3, 1, 167);
    node[123]->nn_param.fcl.weights = 168;
    node[123]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[123]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[123]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_268_160
      var       - node[124]
      name      - Relu_Relu_268
      operation - relu
      input     - [168, 1]
      output    - [168, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_RELU, 1, 1, 160);

    /*-----------------------------------------
      lid       - Gemm_Gemm_269_152
      var       - node[125]
      name      - Gemm_Gemm_269
      operation - fullconnect
      input     - [168, 1]
      filter    - [168, 672]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[125], VSI_NN_OP_FCL, 3, 1, 152);
    node[125]->nn_param.fcl.weights = 672;
    node[125]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[125]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[125]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_271_143
      var       - node[126]
      name      - Add_Add_271
      operation - add
      input     - [672, 1]
                  [1, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[126], VSI_NN_OP_ADD, 2, 1, 143);

    /*-----------------------------------------
      lid       - Clip_Clip_272_137_relun_373
      var       - node[127]
      name      - Clip_Clip_272_137_relun
      operation - relun
      input     - [672, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[127], VSI_NN_OP_RELUN, 1, 1, 373);
    node[127]->nn_param.relun.relu_clamp_top = 6;
    node[127]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_274_129
      var       - node[128]
      name      - Div_Div_274
      operation - real_div
      input     - [672, 1]
                  [1, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[128], VSI_NN_OP_DIVIDE, 2, 1, 129);
    node[128]->nn_param.divide.scale = 1;
    node[128]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[128]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_278_124
      var       - node[129]
      name      - Reshape_Reshape_278
      operation - reshape
      input     - [672, 1]
      output    - [1, 1, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[129], VSI_NN_OP_RESHAPE2, 1, 1, 124);
    node[129]->nn_param.reshape2.size = shape_10;
    node[129]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_279_120
      var       - node[130]
      name      - Mul_Mul_279
      operation - multiply
      input     - [8, 8, 672, 1]
                  [1, 1, 672, 1]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[130], VSI_NN_OP_MULTIPLY, 2, 1, 120);
    node[130]->nn_param.multiply.scale = 1;
    node[130]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[130]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Add_Add_281_125_Clip_Clip_282_121_relun_371_Div_Div_284_117_Mul_Mul_285_115
      var       - node[131]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 672, 1]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[131], VSI_NN_OP_SWISH, 1, 1, 115);
    node[131]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_286_112
      var       - node[132]
      name      - Conv_Conv_286
      operation - convolution
      input     - [8, 8, 672, 1]
      filter    - [1, 1, 672, 112]
      output    - [8, 8, 112, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[132], VSI_NN_OP_CONV2D, 3, 1, 112);
    node[132]->nn_param.conv2d.ksize[0] = 1;
    node[132]->nn_param.conv2d.ksize[1] = 1;
    node[132]->nn_param.conv2d.weights = 112;
    node[132]->nn_param.conv2d.stride[0] = 1;
    node[132]->nn_param.conv2d.stride[1] = 1;
    node[132]->nn_param.conv2d.pad[0] = 0;
    node[132]->nn_param.conv2d.pad[1] = 0;
    node[132]->nn_param.conv2d.pad[2] = 0;
    node[132]->nn_param.conv2d.pad[3] = 0;
    node[132]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[132]->nn_param.conv2d.group = 1;
    node[132]->nn_param.conv2d.dilation[0] = 1;
    node[132]->nn_param.conv2d.dilation[1] = 1;
    node[132]->nn_param.conv2d.multiplier = 0;
    node[132]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[132]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[132]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_288_103
      var       - node[133]
      name      - Add_Add_288
      operation - add
      input     - [8, 8, 112, 1]
                  [8, 8, 112, 1]
      output    - [8, 8, 112, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[133], VSI_NN_OP_ADD, 2, 1, 103);

    /*-----------------------------------------
      lid       - Conv_Conv_289_92
      var       - node[134]
      name      - Conv_Conv_289
      operation - convolution
      input     - [8, 8, 112, 1]
      filter    - [1, 1, 112, 672]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[134], VSI_NN_OP_CONV2D, 3, 1, 92);
    node[134]->nn_param.conv2d.ksize[0] = 1;
    node[134]->nn_param.conv2d.ksize[1] = 1;
    node[134]->nn_param.conv2d.weights = 672;
    node[134]->nn_param.conv2d.stride[0] = 1;
    node[134]->nn_param.conv2d.stride[1] = 1;
    node[134]->nn_param.conv2d.pad[0] = 0;
    node[134]->nn_param.conv2d.pad[1] = 0;
    node[134]->nn_param.conv2d.pad[2] = 0;
    node[134]->nn_param.conv2d.pad[3] = 0;
    node[134]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[134]->nn_param.conv2d.group = 1;
    node[134]->nn_param.conv2d.dilation[0] = 1;
    node[134]->nn_param.conv2d.dilation[1] = 1;
    node[134]->nn_param.conv2d.multiplier = 0;
    node[134]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[134]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[134]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_292_104_Clip_Clip_293_93_relun_369_Div_Div_295_82_Mul_Mul_296_67
      var       - node[135]
      name      - hard_swish
      operation - hard_swish
      input     - [8, 8, 672, 1]
      output    - [8, 8, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[135], VSI_NN_OP_SWISH, 1, 1, 67);
    node[135]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_297_57
      var       - node[136]
      name      - Conv_Conv_297
      operation - convolution
      input     - [8, 8, 672, 1]
      filter    - [5, 5, 672, 1]
      output    - [4, 4, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[136], VSI_NN_OP_CONV2D, 3, 1, 57);
    node[136]->nn_param.conv2d.ksize[0] = 5;
    node[136]->nn_param.conv2d.ksize[1] = 5;
    node[136]->nn_param.conv2d.weights = 672;
    node[136]->nn_param.conv2d.stride[0] = 2;
    node[136]->nn_param.conv2d.stride[1] = 2;
    node[136]->nn_param.conv2d.pad[0] = 2;
    node[136]->nn_param.conv2d.pad[1] = 2;
    node[136]->nn_param.conv2d.pad[2] = 2;
    node[136]->nn_param.conv2d.pad[3] = 2;
    node[136]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[136]->nn_param.conv2d.group = 672;
    node[136]->nn_param.conv2d.dilation[0] = 1;
    node[136]->nn_param.conv2d.dilation[1] = 1;
    node[136]->nn_param.conv2d.multiplier = 1;
    node[136]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[136]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[136]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_305_114
      var       - node[137]
      name      - GlobalAveragePool_GlobalAveragePool_305
      operation - pooling
      input     - [4, 4, 672, 1]
      output    - [1, 1, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[137], VSI_NN_OP_POOL, 1, 1, 114);
    node[137]->nn_param.pool.ksize[0] = 4;
    node[137]->nn_param.pool.ksize[1] = 4;
    node[137]->nn_param.pool.stride[0] = 1;
    node[137]->nn_param.pool.stride[1] = 1;
    node[137]->nn_param.pool.pad[0] = 0;
    node[137]->nn_param.pool.pad[1] = 0;
    node[137]->nn_param.pool.pad[2] = 0;
    node[137]->nn_param.pool.pad[3] = 0;
    node[137]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[137]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[137]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_309_106
      var       - node[138]
      name      - Reshape_Reshape_309
      operation - reshape
      input     - [1, 1, 672, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[138], VSI_NN_OP_RESHAPE2, 1, 1, 106);
    node[138]->nn_param.reshape2.size = shape_11;
    node[138]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_310_105
      var       - node[139]
      name      - Gemm_Gemm_310
      operation - fullconnect
      input     - [672, 1]
      filter    - [672, 168]
      output    - [168, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[139], VSI_NN_OP_FCL, 3, 1, 105);
    node[139]->nn_param.fcl.weights = 168;
    node[139]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[139]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[139]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_311_95
      var       - node[140]
      name      - Relu_Relu_311
      operation - relu
      input     - [168, 1]
      output    - [168, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[140], VSI_NN_OP_RELU, 1, 1, 95);

    /*-----------------------------------------
      lid       - Gemm_Gemm_312_83
      var       - node[141]
      name      - Gemm_Gemm_312
      operation - fullconnect
      input     - [168, 1]
      filter    - [168, 672]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[141], VSI_NN_OP_FCL, 3, 1, 83);
    node[141]->nn_param.fcl.weights = 672;
    node[141]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[141]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[141]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_314_70
      var       - node[142]
      name      - Add_Add_314
      operation - add
      input     - [672, 1]
                  [1, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[142], VSI_NN_OP_ADD, 2, 1, 70);

    /*-----------------------------------------
      lid       - Clip_Clip_315_68_relun_366
      var       - node[143]
      name      - Clip_Clip_315_68_relun
      operation - relun
      input     - [672, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[143], VSI_NN_OP_RELUN, 1, 1, 366);
    node[143]->nn_param.relun.relu_clamp_top = 6;
    node[143]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_317_58
      var       - node[144]
      name      - Div_Div_317
      operation - real_div
      input     - [672, 1]
                  [1, 1]
      output    - [672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[144], VSI_NN_OP_DIVIDE, 2, 1, 58);
    node[144]->nn_param.divide.scale = 1;
    node[144]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[144]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_321_45
      var       - node[145]
      name      - Reshape_Reshape_321
      operation - reshape
      input     - [672, 1]
      output    - [1, 1, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[145], VSI_NN_OP_RESHAPE2, 1, 1, 45);
    node[145]->nn_param.reshape2.size = shape_12;
    node[145]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_322_37
      var       - node[146]
      name      - Mul_Mul_322
      operation - multiply
      input     - [4, 4, 672, 1]
                  [1, 1, 672, 1]
      output    - [4, 4, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[146], VSI_NN_OP_MULTIPLY, 2, 1, 37);
    node[146]->nn_param.multiply.scale = 1;
    node[146]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[146]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Add_Add_324_59_Clip_Clip_325_46_relun_363_Div_Div_327_38_Mul_Mul_328_31
      var       - node[147]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 672, 1]
      output    - [4, 4, 672, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[147], VSI_NN_OP_SWISH, 1, 1, 31);
    node[147]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_329_27
      var       - node[148]
      name      - Conv_Conv_329
      operation - convolution
      input     - [4, 4, 672, 1]
      filter    - [1, 1, 672, 160]
      output    - [4, 4, 160, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[148], VSI_NN_OP_CONV2D, 3, 1, 27);
    node[148]->nn_param.conv2d.ksize[0] = 1;
    node[148]->nn_param.conv2d.ksize[1] = 1;
    node[148]->nn_param.conv2d.weights = 160;
    node[148]->nn_param.conv2d.stride[0] = 1;
    node[148]->nn_param.conv2d.stride[1] = 1;
    node[148]->nn_param.conv2d.pad[0] = 0;
    node[148]->nn_param.conv2d.pad[1] = 0;
    node[148]->nn_param.conv2d.pad[2] = 0;
    node[148]->nn_param.conv2d.pad[3] = 0;
    node[148]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[148]->nn_param.conv2d.group = 1;
    node[148]->nn_param.conv2d.dilation[0] = 1;
    node[148]->nn_param.conv2d.dilation[1] = 1;
    node[148]->nn_param.conv2d.multiplier = 0;
    node[148]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[148]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[148]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_331_96
      var       - node[149]
      name      - Conv_Conv_331
      operation - convolution
      input     - [4, 4, 160, 1]
      filter    - [1, 1, 160, 960]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[149], VSI_NN_OP_CONV2D, 3, 1, 96);
    node[149]->nn_param.conv2d.ksize[0] = 1;
    node[149]->nn_param.conv2d.ksize[1] = 1;
    node[149]->nn_param.conv2d.weights = 960;
    node[149]->nn_param.conv2d.stride[0] = 1;
    node[149]->nn_param.conv2d.stride[1] = 1;
    node[149]->nn_param.conv2d.pad[0] = 0;
    node[149]->nn_param.conv2d.pad[1] = 0;
    node[149]->nn_param.conv2d.pad[2] = 0;
    node[149]->nn_param.conv2d.pad[3] = 0;
    node[149]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[149]->nn_param.conv2d.group = 1;
    node[149]->nn_param.conv2d.dilation[0] = 1;
    node[149]->nn_param.conv2d.dilation[1] = 1;
    node[149]->nn_param.conv2d.multiplier = 0;
    node[149]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[149]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[149]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_334_107_Clip_Clip_335_97_relun_370_Div_Div_337_86_Mul_Mul_338_72
      var       - node[150]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[150], VSI_NN_OP_SWISH, 1, 1, 72);
    node[150]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_339_60
      var       - node[151]
      name      - Conv_Conv_339
      operation - convolution
      input     - [4, 4, 960, 1]
      filter    - [5, 5, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[151], VSI_NN_OP_CONV2D, 3, 1, 60);
    node[151]->nn_param.conv2d.ksize[0] = 5;
    node[151]->nn_param.conv2d.ksize[1] = 5;
    node[151]->nn_param.conv2d.weights = 960;
    node[151]->nn_param.conv2d.stride[0] = 1;
    node[151]->nn_param.conv2d.stride[1] = 1;
    node[151]->nn_param.conv2d.pad[0] = 2;
    node[151]->nn_param.conv2d.pad[1] = 2;
    node[151]->nn_param.conv2d.pad[2] = 2;
    node[151]->nn_param.conv2d.pad[3] = 2;
    node[151]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[151]->nn_param.conv2d.group = 960;
    node[151]->nn_param.conv2d.dilation[0] = 1;
    node[151]->nn_param.conv2d.dilation[1] = 1;
    node[151]->nn_param.conv2d.multiplier = 1;
    node[151]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[151]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[151]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_347_108
      var       - node[152]
      name      - GlobalAveragePool_GlobalAveragePool_347
      operation - pooling
      input     - [4, 4, 960, 1]
      output    - [1, 1, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[152], VSI_NN_OP_POOL, 1, 1, 108);
    node[152]->nn_param.pool.ksize[0] = 4;
    node[152]->nn_param.pool.ksize[1] = 4;
    node[152]->nn_param.pool.stride[0] = 1;
    node[152]->nn_param.pool.stride[1] = 1;
    node[152]->nn_param.pool.pad[0] = 0;
    node[152]->nn_param.pool.pad[1] = 0;
    node[152]->nn_param.pool.pad[2] = 0;
    node[152]->nn_param.pool.pad[3] = 0;
    node[152]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[152]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[152]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_351_100
      var       - node[153]
      name      - Reshape_Reshape_351
      operation - reshape
      input     - [1, 1, 960, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[153], VSI_NN_OP_RESHAPE2, 1, 1, 100);
    node[153]->nn_param.reshape2.size = shape_13;
    node[153]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_352_99
      var       - node[154]
      name      - Gemm_Gemm_352
      operation - fullconnect
      input     - [960, 1]
      filter    - [960, 240]
      output    - [240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[154], VSI_NN_OP_FCL, 3, 1, 99);
    node[154]->nn_param.fcl.weights = 240;
    node[154]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[154]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[154]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_353_89
      var       - node[155]
      name      - Relu_Relu_353
      operation - relu
      input     - [240, 1]
      output    - [240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[155], VSI_NN_OP_RELU, 1, 1, 89);

    /*-----------------------------------------
      lid       - Gemm_Gemm_354_87
      var       - node[156]
      name      - Gemm_Gemm_354
      operation - fullconnect
      input     - [240, 1]
      filter    - [240, 960]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[156], VSI_NN_OP_FCL, 3, 1, 87);
    node[156]->nn_param.fcl.weights = 960;
    node[156]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[156]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[156]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_356_75
      var       - node[157]
      name      - Add_Add_356
      operation - add
      input     - [960, 1]
                  [1, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[157], VSI_NN_OP_ADD, 2, 1, 75);

    /*-----------------------------------------
      lid       - Clip_Clip_357_73_relun_367
      var       - node[158]
      name      - Clip_Clip_357_73_relun
      operation - relun
      input     - [960, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[158], VSI_NN_OP_RELUN, 1, 1, 367);
    node[158]->nn_param.relun.relu_clamp_top = 6;
    node[158]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_359_61
      var       - node[159]
      name      - Div_Div_359
      operation - real_div
      input     - [960, 1]
                  [1, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[159], VSI_NN_OP_DIVIDE, 2, 1, 61);
    node[159]->nn_param.divide.scale = 1;
    node[159]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[159]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_363_49
      var       - node[160]
      name      - Reshape_Reshape_363
      operation - reshape
      input     - [960, 1]
      output    - [1, 1, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[160], VSI_NN_OP_RESHAPE2, 1, 1, 49);
    node[160]->nn_param.reshape2.size = shape_14;
    node[160]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_364_39
      var       - node[161]
      name      - Mul_Mul_364
      operation - multiply
      input     - [4, 4, 960, 1]
                  [1, 1, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[161], VSI_NN_OP_MULTIPLY, 2, 1, 39);
    node[161]->nn_param.multiply.scale = 1;
    node[161]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[161]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Add_Add_366_62_Clip_Clip_367_50_relun_364_Div_Div_369_40_Mul_Mul_370_32
      var       - node[162]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[162], VSI_NN_OP_SWISH, 1, 1, 32);
    node[162]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_371_28
      var       - node[163]
      name      - Conv_Conv_371
      operation - convolution
      input     - [4, 4, 960, 1]
      filter    - [1, 1, 960, 160]
      output    - [4, 4, 160, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[163], VSI_NN_OP_CONV2D, 3, 1, 28);
    node[163]->nn_param.conv2d.ksize[0] = 1;
    node[163]->nn_param.conv2d.ksize[1] = 1;
    node[163]->nn_param.conv2d.weights = 160;
    node[163]->nn_param.conv2d.stride[0] = 1;
    node[163]->nn_param.conv2d.stride[1] = 1;
    node[163]->nn_param.conv2d.pad[0] = 0;
    node[163]->nn_param.conv2d.pad[1] = 0;
    node[163]->nn_param.conv2d.pad[2] = 0;
    node[163]->nn_param.conv2d.pad[3] = 0;
    node[163]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[163]->nn_param.conv2d.group = 1;
    node[163]->nn_param.conv2d.dilation[0] = 1;
    node[163]->nn_param.conv2d.dilation[1] = 1;
    node[163]->nn_param.conv2d.multiplier = 0;
    node[163]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[163]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[163]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_373_22
      var       - node[164]
      name      - Add_Add_373
      operation - add
      input     - [4, 4, 160, 1]
                  [4, 4, 160, 1]
      output    - [4, 4, 160, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[164], VSI_NN_OP_ADD, 2, 1, 22);

    /*-----------------------------------------
      lid       - Conv_Conv_374_77
      var       - node[165]
      name      - Conv_Conv_374
      operation - convolution
      input     - [4, 4, 160, 1]
      filter    - [1, 1, 160, 960]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[165], VSI_NN_OP_CONV2D, 3, 1, 77);
    node[165]->nn_param.conv2d.ksize[0] = 1;
    node[165]->nn_param.conv2d.ksize[1] = 1;
    node[165]->nn_param.conv2d.weights = 960;
    node[165]->nn_param.conv2d.stride[0] = 1;
    node[165]->nn_param.conv2d.stride[1] = 1;
    node[165]->nn_param.conv2d.pad[0] = 0;
    node[165]->nn_param.conv2d.pad[1] = 0;
    node[165]->nn_param.conv2d.pad[2] = 0;
    node[165]->nn_param.conv2d.pad[3] = 0;
    node[165]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[165]->nn_param.conv2d.group = 1;
    node[165]->nn_param.conv2d.dilation[0] = 1;
    node[165]->nn_param.conv2d.dilation[1] = 1;
    node[165]->nn_param.conv2d.multiplier = 0;
    node[165]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[165]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[165]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_377_90_Clip_Clip_378_78_relun_368_Div_Div_380_64_Mul_Mul_381_52
      var       - node[166]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[166], VSI_NN_OP_SWISH, 1, 1, 52);
    node[166]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_382_41
      var       - node[167]
      name      - Conv_Conv_382
      operation - convolution
      input     - [4, 4, 960, 1]
      filter    - [5, 5, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[167], VSI_NN_OP_CONV2D, 3, 1, 41);
    node[167]->nn_param.conv2d.ksize[0] = 5;
    node[167]->nn_param.conv2d.ksize[1] = 5;
    node[167]->nn_param.conv2d.weights = 960;
    node[167]->nn_param.conv2d.stride[0] = 1;
    node[167]->nn_param.conv2d.stride[1] = 1;
    node[167]->nn_param.conv2d.pad[0] = 2;
    node[167]->nn_param.conv2d.pad[1] = 2;
    node[167]->nn_param.conv2d.pad[2] = 2;
    node[167]->nn_param.conv2d.pad[3] = 2;
    node[167]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[167]->nn_param.conv2d.group = 960;
    node[167]->nn_param.conv2d.dilation[0] = 1;
    node[167]->nn_param.conv2d.dilation[1] = 1;
    node[167]->nn_param.conv2d.multiplier = 1;
    node[167]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[167]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[167]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_390_109
      var       - node[168]
      name      - GlobalAveragePool_GlobalAveragePool_390
      operation - pooling
      input     - [4, 4, 960, 1]
      output    - [1, 1, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[168], VSI_NN_OP_POOL, 1, 1, 109);
    node[168]->nn_param.pool.ksize[0] = 4;
    node[168]->nn_param.pool.ksize[1] = 4;
    node[168]->nn_param.pool.stride[0] = 1;
    node[168]->nn_param.pool.stride[1] = 1;
    node[168]->nn_param.pool.pad[0] = 0;
    node[168]->nn_param.pool.pad[1] = 0;
    node[168]->nn_param.pool.pad[2] = 0;
    node[168]->nn_param.pool.pad[3] = 0;
    node[168]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[168]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[168]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_394_102
      var       - node[169]
      name      - Reshape_Reshape_394
      operation - reshape
      input     - [1, 1, 960, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[169], VSI_NN_OP_RESHAPE2, 1, 1, 102);
    node[169]->nn_param.reshape2.size = shape_15;
    node[169]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - Gemm_Gemm_395_91
      var       - node[170]
      name      - Gemm_Gemm_395
      operation - fullconnect
      input     - [960, 1]
      filter    - [960, 240]
      output    - [240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[170], VSI_NN_OP_FCL, 3, 1, 91);
    node[170]->nn_param.fcl.weights = 240;
    node[170]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[170]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[170]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_396_80
      var       - node[171]
      name      - Relu_Relu_396
      operation - relu
      input     - [240, 1]
      output    - [240, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[171], VSI_NN_OP_RELU, 1, 1, 80);

    /*-----------------------------------------
      lid       - Gemm_Gemm_397_65
      var       - node[172]
      name      - Gemm_Gemm_397
      operation - fullconnect
      input     - [240, 1]
      filter    - [240, 960]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[172], VSI_NN_OP_FCL, 3, 1, 65);
    node[172]->nn_param.fcl.weights = 960;
    node[172]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[172]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[172]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_399_55
      var       - node[173]
      name      - Add_Add_399
      operation - add
      input     - [960, 1]
                  [1, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[173], VSI_NN_OP_ADD, 2, 1, 55);

    /*-----------------------------------------
      lid       - Clip_Clip_400_53_relun_365
      var       - node[174]
      name      - Clip_Clip_400_53_relun
      operation - relun
      input     - [960, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[174], VSI_NN_OP_RELUN, 1, 1, 365);
    node[174]->nn_param.relun.relu_clamp_top = 6;
    node[174]->nn_param.relun.relu_clamp_bottom = 0;

    /*-----------------------------------------
      lid       - Div_Div_402_42
      var       - node[175]
      name      - Div_Div_402
      operation - real_div
      input     - [960, 1]
                  [1, 1]
      output    - [960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[175], VSI_NN_OP_DIVIDE, 2, 1, 42);
    node[175]->nn_param.divide.scale = 1;
    node[175]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[175]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Reshape_Reshape_406_34
      var       - node[176]
      name      - Reshape_Reshape_406
      operation - reshape
      input     - [960, 1]
      output    - [1, 1, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[176], VSI_NN_OP_RESHAPE2, 1, 1, 34);
    node[176]->nn_param.reshape2.size = shape_16;
    node[176]->nn_param.reshape2.dim_num = 4;

    /*-----------------------------------------
      lid       - Mul_Mul_407_29
      var       - node[177]
      name      - Mul_Mul_407
      operation - multiply
      input     - [4, 4, 960, 1]
                  [1, 1, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[177], VSI_NN_OP_MULTIPLY, 2, 1, 29);
    node[177]->nn_param.multiply.scale = 1;
    node[177]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[177]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Add_Add_409_43_Clip_Clip_410_35_relun_362_Div_Div_412_30_Mul_Mul_413_26
      var       - node[178]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 960, 1]
      output    - [4, 4, 960, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[178], VSI_NN_OP_SWISH, 1, 1, 26);
    node[178]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Conv_Conv_414_23
      var       - node[179]
      name      - Conv_Conv_414
      operation - convolution
      input     - [4, 4, 960, 1]
      filter    - [1, 1, 960, 160]
      output    - [4, 4, 160, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[179], VSI_NN_OP_CONV2D, 3, 1, 23);
    node[179]->nn_param.conv2d.ksize[0] = 1;
    node[179]->nn_param.conv2d.ksize[1] = 1;
    node[179]->nn_param.conv2d.weights = 160;
    node[179]->nn_param.conv2d.stride[0] = 1;
    node[179]->nn_param.conv2d.stride[1] = 1;
    node[179]->nn_param.conv2d.pad[0] = 0;
    node[179]->nn_param.conv2d.pad[1] = 0;
    node[179]->nn_param.conv2d.pad[2] = 0;
    node[179]->nn_param.conv2d.pad[3] = 0;
    node[179]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[179]->nn_param.conv2d.group = 1;
    node[179]->nn_param.conv2d.dilation[0] = 1;
    node[179]->nn_param.conv2d.dilation[1] = 1;
    node[179]->nn_param.conv2d.multiplier = 0;
    node[179]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[179]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[179]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_416_19
      var       - node[180]
      name      - Add_Add_416
      operation - add
      input     - [4, 4, 160, 1]
                  [4, 4, 160, 1]
      output    - [4, 4, 160, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[180], VSI_NN_OP_ADD, 2, 1, 19);

    /*-----------------------------------------
      lid       - Conv_Conv_417_17
      var       - node[181]
      name      - Conv_Conv_417
      operation - convolution
      input     - [4, 4, 160, 1]
      filter    - [1, 1, 160, 1280]
      output    - [4, 4, 1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[181], VSI_NN_OP_CONV2D, 3, 1, 17);
    node[181]->nn_param.conv2d.ksize[0] = 1;
    node[181]->nn_param.conv2d.ksize[1] = 1;
    node[181]->nn_param.conv2d.weights = 1280;
    node[181]->nn_param.conv2d.stride[0] = 1;
    node[181]->nn_param.conv2d.stride[1] = 1;
    node[181]->nn_param.conv2d.pad[0] = 0;
    node[181]->nn_param.conv2d.pad[1] = 0;
    node[181]->nn_param.conv2d.pad[2] = 0;
    node[181]->nn_param.conv2d.pad[3] = 0;
    node[181]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[181]->nn_param.conv2d.group = 1;
    node[181]->nn_param.conv2d.dilation[0] = 1;
    node[181]->nn_param.conv2d.dilation[1] = 1;
    node[181]->nn_param.conv2d.multiplier = 0;
    node[181]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[181]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[181]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Add_Add_420_18_Clip_Clip_421_15_relun_361_Div_Div_423_12_Mul_Mul_424_11
      var       - node[182]
      name      - hard_swish
      operation - hard_swish
      input     - [4, 4, 1280, 1]
      output    - [4, 4, 1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[182], VSI_NN_OP_SWISH, 1, 1, 11);
    node[182]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - GlobalAveragePool_GlobalAveragePool_425_9
      var       - node[183]
      name      - GlobalAveragePool_GlobalAveragePool_425
      operation - pooling
      input     - [4, 4, 1280, 1]
      output    - [1, 1, 1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[183], VSI_NN_OP_POOL, 1, 1, 9);
    node[183]->nn_param.pool.ksize[0] = 4;
    node[183]->nn_param.pool.ksize[1] = 4;
    node[183]->nn_param.pool.stride[0] = 1;
    node[183]->nn_param.pool.stride[1] = 1;
    node[183]->nn_param.pool.pad[0] = 0;
    node[183]->nn_param.pool.pad[1] = 0;
    node[183]->nn_param.pool.pad[2] = 0;
    node[183]->nn_param.pool.pad[3] = 0;
    node[183]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[183]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[183]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Reshape_Reshape_431_6
      var       - node[184]
      name      - Reshape_Reshape_431
      operation - reshape
      input     - [1, 1, 1280, 1]
      output    - [1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[184], VSI_NN_OP_RESHAPE2, 1, 1, 6);
    node[184]->nn_param.reshape2.size = shape_17;
    node[184]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - BatchNormalization_BatchNormalization_432_4
      var       - node[185]
      name      - BatchNormalization_BatchNormalization_432
      operation - batchnormalize
      input     - [1280, 1]
      output    - [1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[185], VSI_NN_OP_BATCH_NORM, 5, 1, 4);
    node[185]->nn_param.batch_norm.eps = 1e-05;

    /*-----------------------------------------
      lid       - Add_Add_434_10_Clip_Clip_435_7_relun_360_Div_Div_437_5_Mul_Mul_438_3
      var       - node[186]
      name      - hard_swish
      operation - hard_swish
      input     - [1280, 1]
      output    - [1280, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[186], VSI_NN_OP_SWISH, 1, 1, 3);
    node[186]->nn_param.swish.type = VSI_NN_HSWISH;

    /*-----------------------------------------
      lid       - Gemm_Gemm_439_2
      var       - node[187]
      name      - Gemm_Gemm_439
      operation - fullconnect
      input     - [1280, 1]
      filter    - [1280, 2]
      output    - [2, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[187], VSI_NN_OP_FCL, 3, 1, 2);
    node[187]->nn_param.fcl.weights = 2;
    node[187]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[187]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[187]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Softmax_Softmax_440_1
      var       - node[188]
      name      - Softmax_Softmax_440
      operation - softmax
      input     - [2, 1]
      output    - [2, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[188], VSI_NN_OP_SOFTMAX, 1, 1, 1);
    node[188]->nn_param.softmax.beta = 1.0;
    node[188]->nn_param.softmax.axis = 0;

    }
    else
    {
    NEW_VXNODE(node[0], VSI_NN_OP_NBG, 1, 1, 0);
    node[0]->nn_param.nbg.type = VSI_NN_NBG_FILE;
    node[0]->nn_param.nbg.url = data_file_name;

    }

/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_Softmax_Softmax_440/out0_0:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 2;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @actual_input_1_341:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.size[1] = 128;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_FLOAT16);



    if( !inference_with_nbg )
    {
    /* @Initializer_766_54:data
       @Initializer_673_69:data
       @Initializer_719_74:data
       @Initializer_626_130:data
       @Initializer_580_146:data
       @Initializer_463_272:data
       @Initializer_390_281:data
       @Initializer_426_284:data */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_FLOAT16, 6083354, 2);

    /* @Initializer_763_66:data
       @Initializer_670_84:data
       @Initializer_716_88:data
       @Initializer_623_153:data
       @Initializer_577_157:data
       @Initializer_460_287:data
       @Initializer_423_292:data
       @Initializer_387_296:data */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_FLOAT16, 6083352, 2);

    /* @Conv_Conv_0_333:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 16;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_FLOAT16, 20544, 864);

    /* @Conv_Conv_0_333:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_FLOAT32, 20480, 64);

    /* @Conv_Conv_8_339:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 16;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_FLOAT16, 3016896, 288);

    /* @Conv_Conv_8_339:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_FLOAT32, 3016832, 64);

    /* @Conv_Conv_11_332:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 16;
    attr.size[3] = 16;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_FLOAT16, 21472, 512);

    /* @Conv_Conv_11_332:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_FLOAT32, 21408, 64);

    /* @Conv_Conv_14_326:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 16;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_FLOAT16, 128960, 2048);

    /* @Conv_Conv_14_326:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_FLOAT32, 128704, 256);

    /* @Conv_Conv_17_321:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_FLOAT16, 202208, 1152);

    /* @Conv_Conv_17_321:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_FLOAT32, 201952, 256);

    /* @Conv_Conv_20_310:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 24;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_FLOAT16, 375920, 3072);

    /* @Conv_Conv_20_310:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 24;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_FLOAT32, 375824, 96);

    /* @Conv_Conv_22_324:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 24;
    attr.size[3] = 72;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_FLOAT16, 389840, 3456);

    /* @Conv_Conv_22_324:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_FLOAT32, 389552, 288);

    /* @Conv_Conv_25_318:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 72;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_FLOAT16, 669552, 1296);

    /* @Conv_Conv_25_318:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_FLOAT32, 669264, 288);

    /* @Conv_Conv_28_311:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 72;
    attr.size[3] = 24;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_FLOAT16, 975136, 3456);

    /* @Conv_Conv_28_311:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 24;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_FLOAT32, 975040, 96);

    /* @Conv_Conv_31_294:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 24;
    attr.size[3] = 72;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_FLOAT16, 1015168, 3456);

    /* @Conv_Conv_31_294:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_FLOAT32, 1014880, 288);

    /* @Conv_Conv_34_273:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 72;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_FLOAT16, 1597472, 3600);

    /* @Conv_Conv_34_273:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_FLOAT32, 1597184, 288);

    /* @Gemm_Gemm_47_302:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.size[1] = 24;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_FLOAT16, 6060184, 3456);

    /* @Gemm_Gemm_47_302:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 24;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_FLOAT32, 6060088, 96);

    /* @Gemm_Gemm_49_295:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 24;
    attr.size[1] = 72;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_FLOAT16, 6063928, 3456);

    /* @Gemm_Gemm_49_295:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 72;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_FLOAT32, 6063640, 288);

    /* @Conv_Conv_61_255:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 72;
    attr.size[3] = 40;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_FLOAT16, 2994512, 5760);

    /* @Conv_Conv_61_255:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 40;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_FLOAT32, 2994352, 160);

    /* @Conv_Conv_63_297:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 40;
    attr.size[3] = 120;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_FLOAT16, 3000752, 9600);

    /* @Conv_Conv_63_297:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_FLOAT32, 3000272, 480);

    /* @Conv_Conv_66_275:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 120;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_FLOAT16, 3010832, 6000);

    /* @Conv_Conv_66_275:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_FLOAT32, 3010352, 480);

    /* @Gemm_Gemm_79_308:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.size[1] = 32;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_FLOAT16, 6067512, 7680);

    /* @Gemm_Gemm_79_308:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_FLOAT32, 6067384, 128);

    /* @Gemm_Gemm_81_298:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.size[1] = 120;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_FLOAT16, 6075672, 7680);

    /* @Gemm_Gemm_81_298:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_FLOAT32, 6075192, 480);

    /* @Conv_Conv_93_256:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 120;
    attr.size[3] = 40;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_FLOAT16, 3017344, 9600);

    /* @Conv_Conv_93_256:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 40;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_FLOAT32, 3017184, 160);

    /* @Conv_Conv_96_285:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 40;
    attr.size[3] = 120;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_FLOAT16, 3027424, 9600);

    /* @Conv_Conv_96_285:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_FLOAT32, 3026944, 480);

    /* @Conv_Conv_99_264:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 120;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_FLOAT16, 3037504, 6000);

    /* @Conv_Conv_99_264:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_FLOAT32, 3037024, 480);

    /* @Gemm_Gemm_112_299:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.size[1] = 32;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_FLOAT16, 3043632, 7680);

    /* @Gemm_Gemm_112_299:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_FLOAT32, 3043504, 128);

    /* @Gemm_Gemm_114_286:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.size[1] = 120;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_FLOAT16, 3051792, 7680);

    /* @Gemm_Gemm_114_286:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_FLOAT32, 3051312, 480);

    /* @Conv_Conv_126_251:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 120;
    attr.size[3] = 40;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_FLOAT16, 22144, 9600);

    /* @Conv_Conv_126_251:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 40;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_FLOAT32, 21984, 160);

    /* @Conv_Conv_129_239:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 40;
    attr.size[3] = 240;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_FLOAT16, 32704, 19200);

    /* @Conv_Conv_129_239:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_FLOAT32, 31744, 960);

    /* @Conv_Conv_137_210:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 240;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_FLOAT16, 52864, 4320);

    /* @Conv_Conv_137_210:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_FLOAT32, 51904, 960);

    /* @Conv_Conv_145_188:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 240;
    attr.size[3] = 80;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_FLOAT16, 57504, 38400);

    /* @Conv_Conv_145_188:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_FLOAT32, 57184, 320);

    /* @Conv_Conv_147_241:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 200;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_FLOAT16, 96704, 32000);

    /* @Conv_Conv_147_241:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 200;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_FLOAT32, 95904, 800);

    /* @Conv_Conv_155_213:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 200;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_FLOAT16, 131808, 3600);

    /* @Conv_Conv_155_213:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 200;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_FLOAT32, 131008, 800);

    /* @Conv_Conv_163_189:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 200;
    attr.size[3] = 80;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_FLOAT16, 135728, 32000);

    /* @Conv_Conv_163_189:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_FLOAT32, 135408, 320);

    /* @Conv_Conv_166_237:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 184;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_FLOAT16, 168464, 29440);

    /* @Conv_Conv_166_237:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 184;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_FLOAT32, 167728, 736);

    /* @Conv_Conv_174_205:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 184;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_FLOAT16, 198640, 3312);

    /* @Conv_Conv_174_205:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 184;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_FLOAT32, 197904, 736);

    /* @Conv_Conv_182_185:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 184;
    attr.size[3] = 80;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_FLOAT16, 203680, 29440);

    /* @Conv_Conv_182_185:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_FLOAT32, 203360, 320);

    /* @Conv_Conv_185_208:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 184;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_FLOAT16, 233856, 29440);

    /* @Conv_Conv_185_208:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 184;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_FLOAT32, 233120, 736);

    /* @Conv_Conv_193_186:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 184;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_FLOAT16, 264032, 3312);

    /* @Conv_Conv_193_186:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 184;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_FLOAT32, 263296, 736);

    /* @Conv_Conv_201_174:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 184;
    attr.size[3] = 80;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_FLOAT16, 267664, 29440);

    /* @Conv_Conv_201_174:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_FLOAT32, 267344, 320);

    /* @Conv_Conv_204_161:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 480;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_FLOAT16, 299024, 76800);

    /* @Conv_Conv_204_161:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 480;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_FLOAT32, 297104, 1920);

    /* @Conv_Conv_212_138:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 480;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_FLOAT16, 380912, 8640);

    /* @Conv_Conv_212_138:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 480;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_FLOAT32, 378992, 1920);

    /* @Gemm_Gemm_225_164:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 480;
    attr.size[1] = 120;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_FLOAT16, 3059952, 115200);

    /* @Gemm_Gemm_225_164:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_FLOAT32, 3059472, 480);

    /* @Gemm_Gemm_227_156:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 120;
    attr.size[1] = 480;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_FLOAT16, 3177072, 115200);

    /* @Gemm_Gemm_227_156:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 480;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_FLOAT32, 3175152, 1920);

    /* @Conv_Conv_244_119:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 480;
    attr.size[3] = 112;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_FLOAT16, 393744, 107520);

    /* @Conv_Conv_244_119:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 112;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_FLOAT32, 393296, 448);

    /* @Conv_Conv_246_149:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 112;
    attr.size[3] = 672;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_FLOAT16, 503952, 150528);

    /* @Conv_Conv_246_149:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_FLOAT32, 501264, 2688);

    /* @Conv_Conv_254_128:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 672;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_FLOAT16, 657168, 12096);

    /* @Conv_Conv_254_128:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_FLOAT32, 654480, 2688);

    /* @Gemm_Gemm_267_167:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.size[1] = 168;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_FLOAT16, 3292944, 225792);

    /* @Gemm_Gemm_267_167:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 168;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_FLOAT32, 3292272, 672);

    /* @Gemm_Gemm_269_152:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 168;
    attr.size[1] = 672;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_FLOAT16, 3521424, 225792);

    /* @Gemm_Gemm_269_152:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_FLOAT32, 3518736, 2688);

    /* @Conv_Conv_286_112:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 672;
    attr.size[3] = 112;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_FLOAT16, 671296, 150528);

    /* @Conv_Conv_286_112:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 112;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_FLOAT32, 670848, 448);

    /* @Conv_Conv_289_92:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 112;
    attr.size[3] = 672;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_FLOAT16, 824512, 150528);

    /* @Conv_Conv_289_92:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_FLOAT32, 821824, 2688);

    /* @Conv_Conv_297_57:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 672;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_FLOAT16, 981280, 33600);

    /* @Conv_Conv_297_57:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_FLOAT32, 978592, 2688);

    /* @Gemm_Gemm_310_105:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.size[1] = 168;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_FLOAT16, 3747888, 225792);

    /* @Gemm_Gemm_310_105:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 168;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_FLOAT32, 3747216, 672);

    /* @Gemm_Gemm_312_83:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 168;
    attr.size[1] = 672;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_FLOAT16, 3976368, 225792);

    /* @Gemm_Gemm_312_83:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 672;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_FLOAT32, 3973680, 2688);

    /* @Conv_Conv_329_27:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 672;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_FLOAT16, 1019264, 215040);

    /* @Conv_Conv_329_27:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_FLOAT32, 1018624, 640);

    /* @Conv_Conv_331_96:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 160;
    attr.size[3] = 960;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_FLOAT16, 1238144, 307200);

    /* @Conv_Conv_331_96:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_FLOAT32, 1234304, 3840);

    /* @Conv_Conv_339_60:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 960;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_FLOAT16, 1549184, 48000);

    /* @Conv_Conv_339_60:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_FLOAT32, 1545344, 3840);

    /* @Gemm_Gemm_352_99:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.size[1] = 240;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_FLOAT16, 4203120, 460800);

    /* @Gemm_Gemm_352_99:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_FLOAT32, 4202160, 960);

    /* @Gemm_Gemm_354_87:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.size[1] = 960;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_FLOAT16, 4667760, 460800);

    /* @Gemm_Gemm_354_87:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_FLOAT32, 4663920, 3840);

    /* @Conv_Conv_371_28:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 960;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_FLOAT16, 1601712, 307200);

    /* @Conv_Conv_371_28:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_FLOAT32, 1601072, 640);

    /* @Conv_Conv_374_77:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 160;
    attr.size[3] = 960;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_FLOAT16, 1912752, 307200);

    /* @Conv_Conv_374_77:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_FLOAT32, 1908912, 3840);

    /* @Conv_Conv_382_41:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 960;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_FLOAT16, 2223792, 48000);

    /* @Conv_Conv_382_41:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_FLOAT32, 2219952, 3840);

    /* @Gemm_Gemm_395_91:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.size[1] = 240;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_FLOAT16, 5129520, 460800);

    /* @Gemm_Gemm_395_91:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_FLOAT32, 5128560, 960);

    /* @Gemm_Gemm_397_65:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 240;
    attr.size[1] = 960;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[120], attr, VSI_NN_TYPE_FLOAT16, 5594160, 460800);

    /* @Gemm_Gemm_397_65:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 960;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[121], attr, VSI_NN_TYPE_FLOAT32, 5590320, 3840);

    /* @Conv_Conv_414_23:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 960;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[122], attr, VSI_NN_TYPE_FLOAT16, 2272432, 307200);

    /* @Conv_Conv_414_23:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[123], attr, VSI_NN_TYPE_FLOAT32, 2271792, 640);

    /* @Conv_Conv_417_17:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 160;
    attr.size[3] = 1280;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[124], attr, VSI_NN_TYPE_FLOAT16, 2584752, 409600);

    /* @Conv_Conv_417_17:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[125], attr, VSI_NN_TYPE_FLOAT32, 2579632, 5120);

    /* @BatchNormalization_BatchNormalization_432_4:mean */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[126], attr, VSI_NN_TYPE_FLOAT32, 10240, 5120);

    /* @BatchNormalization_BatchNormalization_432_4:variance */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[127], attr, VSI_NN_TYPE_FLOAT32, 15360, 5120);

    /* @BatchNormalization_BatchNormalization_432_4:gamma */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[128], attr, VSI_NN_TYPE_FLOAT32, 5120, 5120);

    /* @BatchNormalization_BatchNormalization_432_4:beta */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[129], attr, VSI_NN_TYPE_FLOAT32, 0, 5120);

    /* @Gemm_Gemm_439_2:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1280;
    attr.size[1] = 2;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[130], attr, VSI_NN_TYPE_FLOAT16, 6054968, 5120);

    /* @Gemm_Gemm_439_2:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 2;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[131], attr, VSI_NN_TYPE_FLOAT32, 6054960, 8);



    /* @Initializer_766_54:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_763_66:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_673_69:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_719_74:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_670_84:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_716_88:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_626_130:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_580_146:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_623_153:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_577_157:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_463_272:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_390_281:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_426_284:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_460_287:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_423_292:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Initializer_387_296:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_0_333:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_3_338_Clip_Clip_4_334_relun_388_Div_Div_6_331_Mul_Mul_7_328:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_8_339:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_10_336:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_11_332:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_13_327:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_14_326:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_16_323:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_17_321:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_19_315:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_20_310:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_22_324:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_24_320:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_25_318:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_27_316:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_28_311:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_30_300:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_31_294:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_33_279:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_34_273:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_42_312:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_46_307:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_47_302:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_48_301:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_49_295:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_51_289:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_52_280_relun_386:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_54_274:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_58_267:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_59_262:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_60_258:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_61_255:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_63_297:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_65_282:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_66_275:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_74_314:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_78_313:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_79_308:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_80_303:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_81_298:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_83_291:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_84_283_relun_387:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_86_276:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_90_269:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_91_263:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_92_259:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_93_256:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_95_250:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_96_285:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_98_270:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_99_264:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_107_309:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_111_304:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_112_299:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_113_293:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_114_286:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_116_278:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_117_271_relun_385:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_119_265:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_123_261:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_124_257:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_125_254:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_126_251:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_128_246:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_129_239:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_132_247_Clip_Clip_133_240_relun_383_Div_Div_135_230_Mul_Mul_136_220:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_137_210:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_140_221_Clip_Clip_141_211_relun_380_Div_Div_143_202_Mul_Mul_144_193:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_145_188:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_147_241:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_150_243_Clip_Clip_151_242_relun_384_Div_Div_153_234_Mul_Mul_154_222:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_155_213:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_158_223_Clip_Clip_159_214_relun_381_Div_Div_161_204_Mul_Mul_162_194:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_163_189:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_165_178:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_166_237:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_169_238_Clip_Clip_170_227_relun_382_Div_Div_172_225_Mul_Mul_173_216:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_174_205:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_177_217_Clip_Clip_178_206_relun_378_Div_Div_180_196_Mul_Mul_181_190:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_182_185:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_184_172:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_185_208:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_188_219_Clip_Clip_189_209_relun_379_Div_Div_191_198_Mul_Mul_192_191:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_193_186:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_196_192_Clip_Clip_197_187_relun_377_Div_Div_199_181_Mul_Mul_200_176:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_201_174:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_203_168:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_204_161:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_207_169_Clip_Clip_208_162_relun_376_Div_Div_210_155_Mul_Mul_211_144:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_212_138:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_220_170:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_224_165:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_225_164:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_226_158:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_227_156:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_229_147:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_230_145_relun_374:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_232_139:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_236_133:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_237_126:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[115]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_239_140_Clip_Clip_240_134_relun_372_Div_Div_242_127_Mul_Mul_243_122:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_244_119:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_246_149:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_249_159_Clip_Clip_250_150_relun_375_Div_Div_252_142_Mul_Mul_253_136:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[119]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_254_128:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_262_177:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_266_171:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[122]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_267_167:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_268_160:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[124]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_269_152:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[125]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_271_143:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[126]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_272_137_relun_373:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[127]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_274_129:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[128]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_278_124:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[129]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_279_120:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[130]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_281_125_Clip_Clip_282_121_relun_371_Div_Div_284_117_Mul_Mul_285_115:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[131]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_286_112:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[132]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_288_103:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[133]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_289_92:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[134]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_292_104_Clip_Clip_293_93_relun_369_Div_Div_295_82_Mul_Mul_296_67:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[135]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_297_57:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[136]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_305_114:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[137]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_309_106:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[138]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_310_105:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[139]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_311_95:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[140]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_312_83:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[141]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_314_70:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[142]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_315_68_relun_366:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[143]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_317_58:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[144]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_321_45:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[145]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_322_37:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[146]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_324_59_Clip_Clip_325_46_relun_363_Div_Div_327_38_Mul_Mul_328_31:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[147]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_329_27:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[148]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_331_96:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[149]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_334_107_Clip_Clip_335_97_relun_370_Div_Div_337_86_Mul_Mul_338_72:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[150]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_339_60:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[151]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_347_108:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[152]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_351_100:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[153]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_352_99:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[154]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_353_89:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[155]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_354_87:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[156]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_356_75:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[157]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_357_73_relun_367:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[158]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_359_61:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[159]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_363_49:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[160]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_364_39:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[161]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_366_62_Clip_Clip_367_50_relun_364_Div_Div_369_40_Mul_Mul_370_32:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[162]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_371_28:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[163]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_373_22:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[164]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_374_77:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[165]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_377_90_Clip_Clip_378_78_relun_368_Div_Div_380_64_Mul_Mul_381_52:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[166]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_382_41:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[167]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_390_109:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[168]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_394_102:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[169]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_395_91:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[170]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Relu_Relu_396_80:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[171]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_397_65:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[172]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_399_55:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[173]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Clip_Clip_400_53_relun_365:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[174]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Div_Div_402_42:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[175]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_406_34:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[176]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_407_29:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[177]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_409_43_Clip_Clip_410_35_relun_362_Div_Div_412_30_Mul_Mul_413_26:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[178]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_414_23:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[179]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_416_19:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[180]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_417_17:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[181]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_420_18_Clip_Clip_421_15_relun_361_Div_Div_423_12_Mul_Mul_424_11:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[182]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @GlobalAveragePool_GlobalAveragePool_425_9:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[183]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Reshape_Reshape_431_6:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[184]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @BatchNormalization_BatchNormalization_432_4:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[185]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_434_10_Clip_Clip_435_7_relun_360_Div_Div_437_5_Mul_Mul_438_3:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[186]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Gemm_Gemm_439_2:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[187]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[16]->input.tensors[0] = norm_tensor[1];
    node[188]->output.tensors[0] = norm_tensor[0];

    /* Initializer_766_54 */
    node[0]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_763_66 */
    node[1]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_673_69 */
    node[2]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_719_74 */
    node[3]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_670_84 */
    node[4]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_716_88 */
    node[5]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_626_130 */
    node[6]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_580_146 */
    node[7]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_623_153 */
    node[8]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_577_157 */
    node[9]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_463_272 */
    node[10]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_390_281 */
    node[11]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_426_284 */
    node[12]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Initializer_460_287 */
    node[13]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_423_292 */
    node[14]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Initializer_387_296 */
    node[15]->input.tensors[0] = const_tensor[1]; /* data_data */

    /* Conv_Conv_0_333 */
    node[16]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* Add_Add_3_338_Clip_Clip_4_334_relun_388_Div_Div_6_331_Mul_Mul_7_328 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];

    /* Conv_Conv_8_339 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* Relu_Relu_10_336 */
    node[19]->input.tensors[0] = node[18]->output.tensors[0];

    /* Conv_Conv_11_332 */
    node[20]->input.tensors[0] = node[19]->output.tensors[0];
    node[20]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[20]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* Add_Add_13_327 */
    node[21]->input.tensors[0] = node[17]->output.tensors[0];
    node[21]->input.tensors[1] = node[20]->output.tensors[0];

    /* Conv_Conv_14_326 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* Relu_Relu_16_323 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];

    /* Conv_Conv_17_321 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];
    node[24]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[24]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* Relu_Relu_19_315 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];

    /* Conv_Conv_20_310 */
    node[26]->input.tensors[0] = node[25]->output.tensors[0];
    node[26]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[26]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* Conv_Conv_22_324 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* Relu_Relu_24_320 */
    node[28]->input.tensors[0] = node[27]->output.tensors[0];

    /* Conv_Conv_25_318 */
    node[29]->input.tensors[0] = node[28]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* Relu_Relu_27_316 */
    node[30]->input.tensors[0] = node[29]->output.tensors[0];

    /* Conv_Conv_28_311 */
    node[31]->input.tensors[0] = node[30]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* Add_Add_30_300 */
    node[32]->input.tensors[0] = node[26]->output.tensors[0];
    node[32]->input.tensors[1] = node[31]->output.tensors[0];

    /* Conv_Conv_31_294 */
    node[33]->input.tensors[0] = node[32]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[33]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* Relu_Relu_33_279 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];

    /* Conv_Conv_34_273 */
    node[35]->input.tensors[0] = node[34]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_42_312 */
    node[36]->input.tensors[0] = node[35]->output.tensors[0];

    /* Reshape_Reshape_46_307 */
    node[37]->input.tensors[0] = node[36]->output.tensors[0];

    /* Gemm_Gemm_47_302 */
    node[38]->input.tensors[0] = node[37]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[38]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* Relu_Relu_48_301 */
    node[39]->input.tensors[0] = node[38]->output.tensors[0];

    /* Gemm_Gemm_49_295 */
    node[40]->input.tensors[0] = node[39]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[40]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* Add_Add_51_289 */
    node[41]->input.tensors[0] = node[40]->output.tensors[0];
    node[41]->input.tensors[1] = node[15]->output.tensors[0];

    /* Clip_Clip_52_280_relun_386 */
    node[42]->input.tensors[0] = node[41]->output.tensors[0];

    /* Div_Div_54_274 */
    node[43]->input.tensors[0] = node[42]->output.tensors[0];
    node[43]->input.tensors[1] = node[11]->output.tensors[0];

    /* Reshape_Reshape_58_267 */
    node[44]->input.tensors[0] = node[43]->output.tensors[0];

    /* Mul_Mul_59_262 */
    node[45]->input.tensors[0] = node[35]->output.tensors[0];
    node[45]->input.tensors[1] = node[44]->output.tensors[0];

    /* Relu_Relu_60_258 */
    node[46]->input.tensors[0] = node[45]->output.tensors[0];

    /* Conv_Conv_61_255 */
    node[47]->input.tensors[0] = node[46]->output.tensors[0];
    node[47]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[47]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* Conv_Conv_63_297 */
    node[48]->input.tensors[0] = node[47]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* Relu_Relu_65_282 */
    node[49]->input.tensors[0] = node[48]->output.tensors[0];

    /* Conv_Conv_66_275 */
    node[50]->input.tensors[0] = node[49]->output.tensors[0];
    node[50]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[50]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_74_314 */
    node[51]->input.tensors[0] = node[50]->output.tensors[0];

    /* Reshape_Reshape_78_313 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];

    /* Gemm_Gemm_79_308 */
    node[53]->input.tensors[0] = node[52]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[53]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* Relu_Relu_80_303 */
    node[54]->input.tensors[0] = node[53]->output.tensors[0];

    /* Gemm_Gemm_81_298 */
    node[55]->input.tensors[0] = node[54]->output.tensors[0];
    node[55]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[55]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* Add_Add_83_291 */
    node[56]->input.tensors[0] = node[55]->output.tensors[0];
    node[56]->input.tensors[1] = node[14]->output.tensors[0];

    /* Clip_Clip_84_283_relun_387 */
    node[57]->input.tensors[0] = node[56]->output.tensors[0];

    /* Div_Div_86_276 */
    node[58]->input.tensors[0] = node[57]->output.tensors[0];
    node[58]->input.tensors[1] = node[12]->output.tensors[0];

    /* Reshape_Reshape_90_269 */
    node[59]->input.tensors[0] = node[58]->output.tensors[0];

    /* Mul_Mul_91_263 */
    node[60]->input.tensors[0] = node[50]->output.tensors[0];
    node[60]->input.tensors[1] = node[59]->output.tensors[0];

    /* Relu_Relu_92_259 */
    node[61]->input.tensors[0] = node[60]->output.tensors[0];

    /* Conv_Conv_93_256 */
    node[62]->input.tensors[0] = node[61]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* Add_Add_95_250 */
    node[63]->input.tensors[0] = node[47]->output.tensors[0];
    node[63]->input.tensors[1] = node[62]->output.tensors[0];

    /* Conv_Conv_96_285 */
    node[64]->input.tensors[0] = node[63]->output.tensors[0];
    node[64]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[64]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* Relu_Relu_98_270 */
    node[65]->input.tensors[0] = node[64]->output.tensors[0];

    /* Conv_Conv_99_264 */
    node[66]->input.tensors[0] = node[65]->output.tensors[0];
    node[66]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[66]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_107_309 */
    node[67]->input.tensors[0] = node[66]->output.tensors[0];

    /* Reshape_Reshape_111_304 */
    node[68]->input.tensors[0] = node[67]->output.tensors[0];

    /* Gemm_Gemm_112_299 */
    node[69]->input.tensors[0] = node[68]->output.tensors[0];
    node[69]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[69]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* Relu_Relu_113_293 */
    node[70]->input.tensors[0] = node[69]->output.tensors[0];

    /* Gemm_Gemm_114_286 */
    node[71]->input.tensors[0] = node[70]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[71]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* Add_Add_116_278 */
    node[72]->input.tensors[0] = node[71]->output.tensors[0];
    node[72]->input.tensors[1] = node[13]->output.tensors[0];

    /* Clip_Clip_117_271_relun_385 */
    node[73]->input.tensors[0] = node[72]->output.tensors[0];

    /* Div_Div_119_265 */
    node[74]->input.tensors[0] = node[73]->output.tensors[0];
    node[74]->input.tensors[1] = node[10]->output.tensors[0];

    /* Reshape_Reshape_123_261 */
    node[75]->input.tensors[0] = node[74]->output.tensors[0];

    /* Mul_Mul_124_257 */
    node[76]->input.tensors[0] = node[66]->output.tensors[0];
    node[76]->input.tensors[1] = node[75]->output.tensors[0];

    /* Relu_Relu_125_254 */
    node[77]->input.tensors[0] = node[76]->output.tensors[0];

    /* Conv_Conv_126_251 */
    node[78]->input.tensors[0] = node[77]->output.tensors[0];
    node[78]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[78]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* Add_Add_128_246 */
    node[79]->input.tensors[0] = node[63]->output.tensors[0];
    node[79]->input.tensors[1] = node[78]->output.tensors[0];

    /* Conv_Conv_129_239 */
    node[80]->input.tensors[0] = node[79]->output.tensors[0];
    node[80]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[80]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* Add_Add_132_247_Clip_Clip_133_240_relun_383_Div_Div_135_230_Mul_Mul_136_220 */
    node[81]->input.tensors[0] = node[80]->output.tensors[0];

    /* Conv_Conv_137_210 */
    node[82]->input.tensors[0] = node[81]->output.tensors[0];
    node[82]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[82]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* Add_Add_140_221_Clip_Clip_141_211_relun_380_Div_Div_143_202_Mul_Mul_144_193 */
    node[83]->input.tensors[0] = node[82]->output.tensors[0];

    /* Conv_Conv_145_188 */
    node[84]->input.tensors[0] = node[83]->output.tensors[0];
    node[84]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[84]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* Conv_Conv_147_241 */
    node[85]->input.tensors[0] = node[84]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* Add_Add_150_243_Clip_Clip_151_242_relun_384_Div_Div_153_234_Mul_Mul_154_222 */
    node[86]->input.tensors[0] = node[85]->output.tensors[0];

    /* Conv_Conv_155_213 */
    node[87]->input.tensors[0] = node[86]->output.tensors[0];
    node[87]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[87]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* Add_Add_158_223_Clip_Clip_159_214_relun_381_Div_Div_161_204_Mul_Mul_162_194 */
    node[88]->input.tensors[0] = node[87]->output.tensors[0];

    /* Conv_Conv_163_189 */
    node[89]->input.tensors[0] = node[88]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[60]; /* data_weight */
    node[89]->input.tensors[2] = const_tensor[61]; /* data_bias */

    /* Add_Add_165_178 */
    node[90]->input.tensors[0] = node[84]->output.tensors[0];
    node[90]->input.tensors[1] = node[89]->output.tensors[0];

    /* Conv_Conv_166_237 */
    node[91]->input.tensors[0] = node[90]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[62]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* Add_Add_169_238_Clip_Clip_170_227_relun_382_Div_Div_172_225_Mul_Mul_173_216 */
    node[92]->input.tensors[0] = node[91]->output.tensors[0];

    /* Conv_Conv_174_205 */
    node[93]->input.tensors[0] = node[92]->output.tensors[0];
    node[93]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[93]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* Add_Add_177_217_Clip_Clip_178_206_relun_378_Div_Div_180_196_Mul_Mul_181_190 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];

    /* Conv_Conv_182_185 */
    node[95]->input.tensors[0] = node[94]->output.tensors[0];
    node[95]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[95]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* Add_Add_184_172 */
    node[96]->input.tensors[0] = node[90]->output.tensors[0];
    node[96]->input.tensors[1] = node[95]->output.tensors[0];

    /* Conv_Conv_185_208 */
    node[97]->input.tensors[0] = node[96]->output.tensors[0];
    node[97]->input.tensors[1] = const_tensor[68]; /* data_weight */
    node[97]->input.tensors[2] = const_tensor[69]; /* data_bias */

    /* Add_Add_188_219_Clip_Clip_189_209_relun_379_Div_Div_191_198_Mul_Mul_192_191 */
    node[98]->input.tensors[0] = node[97]->output.tensors[0];

    /* Conv_Conv_193_186 */
    node[99]->input.tensors[0] = node[98]->output.tensors[0];
    node[99]->input.tensors[1] = const_tensor[70]; /* data_weight */
    node[99]->input.tensors[2] = const_tensor[71]; /* data_bias */

    /* Add_Add_196_192_Clip_Clip_197_187_relun_377_Div_Div_199_181_Mul_Mul_200_176 */
    node[100]->input.tensors[0] = node[99]->output.tensors[0];

    /* Conv_Conv_201_174 */
    node[101]->input.tensors[0] = node[100]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* Add_Add_203_168 */
    node[102]->input.tensors[0] = node[96]->output.tensors[0];
    node[102]->input.tensors[1] = node[101]->output.tensors[0];

    /* Conv_Conv_204_161 */
    node[103]->input.tensors[0] = node[102]->output.tensors[0];
    node[103]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[103]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* Add_Add_207_169_Clip_Clip_208_162_relun_376_Div_Div_210_155_Mul_Mul_211_144 */
    node[104]->input.tensors[0] = node[103]->output.tensors[0];

    /* Conv_Conv_212_138 */
    node[105]->input.tensors[0] = node[104]->output.tensors[0];
    node[105]->input.tensors[1] = const_tensor[76]; /* data_weight */
    node[105]->input.tensors[2] = const_tensor[77]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_220_170 */
    node[106]->input.tensors[0] = node[105]->output.tensors[0];

    /* Reshape_Reshape_224_165 */
    node[107]->input.tensors[0] = node[106]->output.tensors[0];

    /* Gemm_Gemm_225_164 */
    node[108]->input.tensors[0] = node[107]->output.tensors[0];
    node[108]->input.tensors[1] = const_tensor[78]; /* data_weight */
    node[108]->input.tensors[2] = const_tensor[79]; /* data_bias */

    /* Relu_Relu_226_158 */
    node[109]->input.tensors[0] = node[108]->output.tensors[0];

    /* Gemm_Gemm_227_156 */
    node[110]->input.tensors[0] = node[109]->output.tensors[0];
    node[110]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[110]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* Add_Add_229_147 */
    node[111]->input.tensors[0] = node[110]->output.tensors[0];
    node[111]->input.tensors[1] = node[9]->output.tensors[0];

    /* Clip_Clip_230_145_relun_374 */
    node[112]->input.tensors[0] = node[111]->output.tensors[0];

    /* Div_Div_232_139 */
    node[113]->input.tensors[0] = node[112]->output.tensors[0];
    node[113]->input.tensors[1] = node[7]->output.tensors[0];

    /* Reshape_Reshape_236_133 */
    node[114]->input.tensors[0] = node[113]->output.tensors[0];

    /* Mul_Mul_237_126 */
    node[115]->input.tensors[0] = node[105]->output.tensors[0];
    node[115]->input.tensors[1] = node[114]->output.tensors[0];

    /* Add_Add_239_140_Clip_Clip_240_134_relun_372_Div_Div_242_127_Mul_Mul_243_122 */
    node[116]->input.tensors[0] = node[115]->output.tensors[0];

    /* Conv_Conv_244_119 */
    node[117]->input.tensors[0] = node[116]->output.tensors[0];
    node[117]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[117]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* Conv_Conv_246_149 */
    node[118]->input.tensors[0] = node[117]->output.tensors[0];
    node[118]->input.tensors[1] = const_tensor[84]; /* data_weight */
    node[118]->input.tensors[2] = const_tensor[85]; /* data_bias */

    /* Add_Add_249_159_Clip_Clip_250_150_relun_375_Div_Div_252_142_Mul_Mul_253_136 */
    node[119]->input.tensors[0] = node[118]->output.tensors[0];

    /* Conv_Conv_254_128 */
    node[120]->input.tensors[0] = node[119]->output.tensors[0];
    node[120]->input.tensors[1] = const_tensor[86]; /* data_weight */
    node[120]->input.tensors[2] = const_tensor[87]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_262_177 */
    node[121]->input.tensors[0] = node[120]->output.tensors[0];

    /* Reshape_Reshape_266_171 */
    node[122]->input.tensors[0] = node[121]->output.tensors[0];

    /* Gemm_Gemm_267_167 */
    node[123]->input.tensors[0] = node[122]->output.tensors[0];
    node[123]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[123]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* Relu_Relu_268_160 */
    node[124]->input.tensors[0] = node[123]->output.tensors[0];

    /* Gemm_Gemm_269_152 */
    node[125]->input.tensors[0] = node[124]->output.tensors[0];
    node[125]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[125]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* Add_Add_271_143 */
    node[126]->input.tensors[0] = node[125]->output.tensors[0];
    node[126]->input.tensors[1] = node[8]->output.tensors[0];

    /* Clip_Clip_272_137_relun_373 */
    node[127]->input.tensors[0] = node[126]->output.tensors[0];

    /* Div_Div_274_129 */
    node[128]->input.tensors[0] = node[127]->output.tensors[0];
    node[128]->input.tensors[1] = node[6]->output.tensors[0];

    /* Reshape_Reshape_278_124 */
    node[129]->input.tensors[0] = node[128]->output.tensors[0];

    /* Mul_Mul_279_120 */
    node[130]->input.tensors[0] = node[120]->output.tensors[0];
    node[130]->input.tensors[1] = node[129]->output.tensors[0];

    /* Add_Add_281_125_Clip_Clip_282_121_relun_371_Div_Div_284_117_Mul_Mul_285_115 */
    node[131]->input.tensors[0] = node[130]->output.tensors[0];

    /* Conv_Conv_286_112 */
    node[132]->input.tensors[0] = node[131]->output.tensors[0];
    node[132]->input.tensors[1] = const_tensor[92]; /* data_weight */
    node[132]->input.tensors[2] = const_tensor[93]; /* data_bias */

    /* Add_Add_288_103 */
    node[133]->input.tensors[0] = node[117]->output.tensors[0];
    node[133]->input.tensors[1] = node[132]->output.tensors[0];

    /* Conv_Conv_289_92 */
    node[134]->input.tensors[0] = node[133]->output.tensors[0];
    node[134]->input.tensors[1] = const_tensor[94]; /* data_weight */
    node[134]->input.tensors[2] = const_tensor[95]; /* data_bias */

    /* Add_Add_292_104_Clip_Clip_293_93_relun_369_Div_Div_295_82_Mul_Mul_296_67 */
    node[135]->input.tensors[0] = node[134]->output.tensors[0];

    /* Conv_Conv_297_57 */
    node[136]->input.tensors[0] = node[135]->output.tensors[0];
    node[136]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[136]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_305_114 */
    node[137]->input.tensors[0] = node[136]->output.tensors[0];

    /* Reshape_Reshape_309_106 */
    node[138]->input.tensors[0] = node[137]->output.tensors[0];

    /* Gemm_Gemm_310_105 */
    node[139]->input.tensors[0] = node[138]->output.tensors[0];
    node[139]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[139]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* Relu_Relu_311_95 */
    node[140]->input.tensors[0] = node[139]->output.tensors[0];

    /* Gemm_Gemm_312_83 */
    node[141]->input.tensors[0] = node[140]->output.tensors[0];
    node[141]->input.tensors[1] = const_tensor[100]; /* data_weight */
    node[141]->input.tensors[2] = const_tensor[101]; /* data_bias */

    /* Add_Add_314_70 */
    node[142]->input.tensors[0] = node[141]->output.tensors[0];
    node[142]->input.tensors[1] = node[4]->output.tensors[0];

    /* Clip_Clip_315_68_relun_366 */
    node[143]->input.tensors[0] = node[142]->output.tensors[0];

    /* Div_Div_317_58 */
    node[144]->input.tensors[0] = node[143]->output.tensors[0];
    node[144]->input.tensors[1] = node[2]->output.tensors[0];

    /* Reshape_Reshape_321_45 */
    node[145]->input.tensors[0] = node[144]->output.tensors[0];

    /* Mul_Mul_322_37 */
    node[146]->input.tensors[0] = node[136]->output.tensors[0];
    node[146]->input.tensors[1] = node[145]->output.tensors[0];

    /* Add_Add_324_59_Clip_Clip_325_46_relun_363_Div_Div_327_38_Mul_Mul_328_31 */
    node[147]->input.tensors[0] = node[146]->output.tensors[0];

    /* Conv_Conv_329_27 */
    node[148]->input.tensors[0] = node[147]->output.tensors[0];
    node[148]->input.tensors[1] = const_tensor[102]; /* data_weight */
    node[148]->input.tensors[2] = const_tensor[103]; /* data_bias */

    /* Conv_Conv_331_96 */
    node[149]->input.tensors[0] = node[148]->output.tensors[0];
    node[149]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[149]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* Add_Add_334_107_Clip_Clip_335_97_relun_370_Div_Div_337_86_Mul_Mul_338_72 */
    node[150]->input.tensors[0] = node[149]->output.tensors[0];

    /* Conv_Conv_339_60 */
    node[151]->input.tensors[0] = node[150]->output.tensors[0];
    node[151]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[151]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_347_108 */
    node[152]->input.tensors[0] = node[151]->output.tensors[0];

    /* Reshape_Reshape_351_100 */
    node[153]->input.tensors[0] = node[152]->output.tensors[0];

    /* Gemm_Gemm_352_99 */
    node[154]->input.tensors[0] = node[153]->output.tensors[0];
    node[154]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[154]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* Relu_Relu_353_89 */
    node[155]->input.tensors[0] = node[154]->output.tensors[0];

    /* Gemm_Gemm_354_87 */
    node[156]->input.tensors[0] = node[155]->output.tensors[0];
    node[156]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[156]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* Add_Add_356_75 */
    node[157]->input.tensors[0] = node[156]->output.tensors[0];
    node[157]->input.tensors[1] = node[5]->output.tensors[0];

    /* Clip_Clip_357_73_relun_367 */
    node[158]->input.tensors[0] = node[157]->output.tensors[0];

    /* Div_Div_359_61 */
    node[159]->input.tensors[0] = node[158]->output.tensors[0];
    node[159]->input.tensors[1] = node[3]->output.tensors[0];

    /* Reshape_Reshape_363_49 */
    node[160]->input.tensors[0] = node[159]->output.tensors[0];

    /* Mul_Mul_364_39 */
    node[161]->input.tensors[0] = node[151]->output.tensors[0];
    node[161]->input.tensors[1] = node[160]->output.tensors[0];

    /* Add_Add_366_62_Clip_Clip_367_50_relun_364_Div_Div_369_40_Mul_Mul_370_32 */
    node[162]->input.tensors[0] = node[161]->output.tensors[0];

    /* Conv_Conv_371_28 */
    node[163]->input.tensors[0] = node[162]->output.tensors[0];
    node[163]->input.tensors[1] = const_tensor[112]; /* data_weight */
    node[163]->input.tensors[2] = const_tensor[113]; /* data_bias */

    /* Add_Add_373_22 */
    node[164]->input.tensors[0] = node[148]->output.tensors[0];
    node[164]->input.tensors[1] = node[163]->output.tensors[0];

    /* Conv_Conv_374_77 */
    node[165]->input.tensors[0] = node[164]->output.tensors[0];
    node[165]->input.tensors[1] = const_tensor[114]; /* data_weight */
    node[165]->input.tensors[2] = const_tensor[115]; /* data_bias */

    /* Add_Add_377_90_Clip_Clip_378_78_relun_368_Div_Div_380_64_Mul_Mul_381_52 */
    node[166]->input.tensors[0] = node[165]->output.tensors[0];

    /* Conv_Conv_382_41 */
    node[167]->input.tensors[0] = node[166]->output.tensors[0];
    node[167]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[167]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* GlobalAveragePool_GlobalAveragePool_390_109 */
    node[168]->input.tensors[0] = node[167]->output.tensors[0];

    /* Reshape_Reshape_394_102 */
    node[169]->input.tensors[0] = node[168]->output.tensors[0];

    /* Gemm_Gemm_395_91 */
    node[170]->input.tensors[0] = node[169]->output.tensors[0];
    node[170]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[170]->input.tensors[2] = const_tensor[119]; /* data_bias */

    /* Relu_Relu_396_80 */
    node[171]->input.tensors[0] = node[170]->output.tensors[0];

    /* Gemm_Gemm_397_65 */
    node[172]->input.tensors[0] = node[171]->output.tensors[0];
    node[172]->input.tensors[1] = const_tensor[120]; /* data_weight */
    node[172]->input.tensors[2] = const_tensor[121]; /* data_bias */

    /* Add_Add_399_55 */
    node[173]->input.tensors[0] = node[172]->output.tensors[0];
    node[173]->input.tensors[1] = node[1]->output.tensors[0];

    /* Clip_Clip_400_53_relun_365 */
    node[174]->input.tensors[0] = node[173]->output.tensors[0];

    /* Div_Div_402_42 */
    node[175]->input.tensors[0] = node[174]->output.tensors[0];
    node[175]->input.tensors[1] = node[0]->output.tensors[0];

    /* Reshape_Reshape_406_34 */
    node[176]->input.tensors[0] = node[175]->output.tensors[0];

    /* Mul_Mul_407_29 */
    node[177]->input.tensors[0] = node[167]->output.tensors[0];
    node[177]->input.tensors[1] = node[176]->output.tensors[0];

    /* Add_Add_409_43_Clip_Clip_410_35_relun_362_Div_Div_412_30_Mul_Mul_413_26 */
    node[178]->input.tensors[0] = node[177]->output.tensors[0];

    /* Conv_Conv_414_23 */
    node[179]->input.tensors[0] = node[178]->output.tensors[0];
    node[179]->input.tensors[1] = const_tensor[122]; /* data_weight */
    node[179]->input.tensors[2] = const_tensor[123]; /* data_bias */

    /* Add_Add_416_19 */
    node[180]->input.tensors[0] = node[164]->output.tensors[0];
    node[180]->input.tensors[1] = node[179]->output.tensors[0];

    /* Conv_Conv_417_17 */
    node[181]->input.tensors[0] = node[180]->output.tensors[0];
    node[181]->input.tensors[1] = const_tensor[124]; /* data_weight */
    node[181]->input.tensors[2] = const_tensor[125]; /* data_bias */

    /* Add_Add_420_18_Clip_Clip_421_15_relun_361_Div_Div_423_12_Mul_Mul_424_11 */
    node[182]->input.tensors[0] = node[181]->output.tensors[0];

    /* GlobalAveragePool_GlobalAveragePool_425_9 */
    node[183]->input.tensors[0] = node[182]->output.tensors[0];

    /* Reshape_Reshape_431_6 */
    node[184]->input.tensors[0] = node[183]->output.tensors[0];

    /* BatchNormalization_BatchNormalization_432_4 */
    node[185]->input.tensors[0] = node[184]->output.tensors[0];
    node[185]->input.tensors[1] = const_tensor[126]; /* data_mean */
    node[185]->input.tensors[2] = const_tensor[127]; /* data_variance */
    node[185]->input.tensors[3] = const_tensor[128]; /* data_gamma */
    node[185]->input.tensors[4] = const_tensor[129]; /* data_beta */

    /* Add_Add_434_10_Clip_Clip_435_7_relun_360_Div_Div_437_5_Mul_Mul_438_3 */
    node[186]->input.tensors[0] = node[185]->output.tensors[0];

    /* Gemm_Gemm_439_2 */
    node[187]->input.tensors[0] = node[186]->output.tensors[0];
    node[187]->input.tensors[1] = const_tensor[130]; /* data_weight */
    node[187]->input.tensors[2] = const_tensor[131]; /* data_bias */

    /* Softmax_Softmax_440_1 */
    node[188]->input.tensors[0] = node[187]->output.tensors[0];


    }
    else
    {
    node[0]->output.tensors[0] = norm_tensor[0];
    node[0]->input.tensors[0] = norm_tensor[1];

    }
    graph->output.tensors[0] = norm_tensor[0];
    graph->input.tensors[0] = norm_tensor[1];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );


    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseAntiSpoof( graph, release_ctx );

    return NULL;
} /* vnn_CreateAntiSpoof() */

void vnn_ReleaseAntiSpoof
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vnn_ReleaseAntiSpoof() */

