/****************************************************************************
*   Generated by ACUITY 6.21.1
*   Match ovxlib 1.1.30
*
*   Neural Network appliction post-process source file
****************************************************************************/
/*-------------------------------------------
                Includes
-------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <numeric>

#include "vsi_nn_pub.h"

#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/dnn.hpp>

extern "C" {
#include "vsi_nn_pub.h"
#include "vsi_nn_types.h"
#include "vsi_nn_graph.h"
#include "vsi_nn_op_proposal.h"
#include "vnn_global.h"
//#include "vnn_post_process.h"
}

#include "vnn_post_process_facedetector.hpp"


#define _BASETSD_H
#define DETECT_RESULT_IMPL 1

/*-------------------------------------------
                  Variable definitions
-------------------------------------------*/

#if DETECT_RESULT_IMPL
const std::vector<int> stride_list = {8, 16, 32}; //the stride of each output layer, the stride of feature maps in each layer
const int num_strides = stride_list.size();
const int keep_top_k = 750;
const bool clip = false;
const float confidence_threshold = 0.02f;
const float nms_threshold = 0.4f;
const float vis_thres = 0.6f;    
const std::vector<std::vector<float>> min_sizes = {{16, 32}, {64, 128}, {256, 512}}; //the image size of the model input
const std::vector<float>& variances = {0.1f, 0.2f};
#endif

/*{graph_output_idx, postprocess}*/
const static vsi_nn_postprocess_map_element_t* postprocess_map = NULL;
/*-------------------------------------------
                  Functions
-------------------------------------------*/
//Add by yingwei
#if DETECT_RESULT_IMPL

std::vector<Anchor> generate_prior_boxes(int image_width, int image_height, const std::vector<int>& strides, const std::vector<std::vector<float>>& min_sizes, bool clip) {
    std::vector<Anchor> anchors;

    for (size_t k = 0; k < strides.size(); k++) {
        int stride = strides[k];
        int feature_map_width = std::ceil(static_cast<float>(image_width) / stride);
        int feature_map_height = std::ceil(static_cast<float>(image_height) / stride);

        for (int i = 0; i < feature_map_height; i++) {
            for (int j = 0; j < feature_map_width; j++) {
                float cx = (j + 0.5f) * stride / image_width;
                float cy = (i + 0.5f) * stride / image_height;
                for (float min_size : min_sizes[k]) {
                    float w = min_size / image_width;
                    float h = min_size / image_height;
                    Anchor anchor = {cx, cy, w, h};
                    anchors.push_back(anchor);
                }
            }
        }
    }
 
    // Optionally clip the anchors
    if (clip) {
        for (auto& anchor : anchors) {
            anchor.cx = std::min(std::max(anchor.cx, 0.0f), 1.0f);
            anchor.cy = std::min(std::max(anchor.cy, 0.0f), 1.0f);
        }
    }

    return anchors;
}

std::vector<BoundingBox> decode_boxes(const std::vector<Prediction>& locs, 
                                      const std::vector<Anchor>& anchors, 
                                      const std::vector<float>& variances) 
{
    std::vector<BoundingBox> boxes;

    for (size_t i = 0; i < locs.size(); ++i) {
        const Prediction& loc = locs[i];
        const Anchor& prior = anchors[i];

        float cx = prior.cx + loc.c_x * variances[0] * prior.w;
        float cy = prior.cy + loc.c_y * variances[0] * prior.h;
        float w = prior.w * exp(loc.w * variances[1]);
        float h = prior.h * exp(loc.h * variances[1]);

        float x1 = (cx - 0.5f * w);
        float y1 = (cy - 0.5f * h);
        float x2 = (cx + 0.5f * w);
        float y2 = (cy + 0.5f * h);        

        boxes.emplace_back(x1, y1, x2 - x1, y2 - y1);
    }
    return boxes;
}

std::vector<std::vector<float>> decode_landmarks(const std::vector<Landmark>& landmarks, const std::vector<Anchor>& anchors, const std::vector<float>& variances) 
{
    std::vector<std::vector<float>> decoded_landmarks(landmarks.size(), std::vector<float>(10)); 
    for (size_t i = 0; i < landmarks.size(); ++i) {
        const auto& anchor = anchors[i];
        const auto& landms = landmarks[i];

        for (int j = 0; j < 5; ++j) {
            float x_offset = landms.points[j].x * variances[0] * anchor.w; // x offset
            float y_offset = landms.points[j].y * variances[0] * anchor.h; // y offset

            decoded_landmarks[i][2 * j]     = anchor.cx + x_offset; // x 
            decoded_landmarks[i][2 * j + 1] = anchor.cy + y_offset; // y
        }
    }

    return decoded_landmarks;
}

void convert_uint8_to_float(uint8_t* input, float* output, size_t size) {
    for (size_t i = 0; i < size; i++) {
        output[i] = static_cast<float>(input[i]);
    }
}
#endif

float compute_iou(const cv::Rect& box1, const cv::Rect& box2) {
    int x1 = std::max(box1.x, box2.x);
    int y1 = std::max(box1.y, box2.y);
    int x2 = std::min(box1.x + box1.width, box2.x + box2.width);
    int y2 = std::min(box1.y + box1.height, box2.y + box2.height);

    int width = std::max(0, x2 - x1);
    int height = std::max(0, y2 - y1);
    float inter_area = width * height;

    float box1_area = box1.width * box1.height;
    float box2_area = box2.width * box2.height;
    float union_area = box1_area + box2_area - inter_area;

    return inter_area / union_area;
}

void apply_nms(const std::vector<cv::Rect>& boxes, const std::vector<float>& scores, float nms_threshold, std::vector<int>& keep) {
    std::vector<int> indices(boxes.size());
    for (size_t i = 0; i < indices.size(); ++i) {
        indices[i] = i;
    }

    std::sort(indices.begin(), indices.end(), [&](int i1, int i2) {
        return scores[i1] > scores[i2];
    });

    std::vector<bool> selected(indices.size(), true);
    for (size_t i = 0; i < indices.size(); ++i) {
        if (!selected[indices[i]]) continue;
        for (size_t j = i + 1; j < indices.size(); ++j) {
            if (!selected[indices[j]]) continue;
            if (compute_iou(boxes[indices[i]], boxes[indices[j]]) > nms_threshold) {
                selected[indices[j]] = false;
            }
        }
    }

    keep.clear();
    for (size_t i = 0; i < indices.size(); ++i) {
        if (selected[indices[i]]) {
            keep.push_back(indices[i]);
        }
    }    
}

static void post_proc_process(vsi_nn_graph_t *graph, std::vector<FaceObject>& faces) {
    //get output tensor
    vsi_nn_tensor_t *bbox_tensor = vsi_nn_GetTensor(graph, graph->output.tensors[0]);
    vsi_nn_tensor_t *conf_tensor = vsi_nn_GetTensor(graph, graph->output.tensors[1]);
    vsi_nn_tensor_t *landms_tensor = vsi_nn_GetTensor(graph, graph->output.tensors[2]);  

    //get tensor size
    vsi_size_t sz_bbox = 1, sz_conf = 1, sz_landms = 1;
    for (size_t i = 0; i < bbox_tensor->attr.dim_num; i++) {
        sz_bbox *= bbox_tensor->attr.size[i];
    }
    for (size_t i = 0; i < conf_tensor->attr.dim_num; i++) {
        sz_conf *= conf_tensor->attr.size[i];
    }
    for (size_t i = 0; i < landms_tensor->attr.dim_num; i++) {
        sz_landms *= landms_tensor->attr.size[i];
    }

    //get stride
    vsi_size_t stride_bbox = (vsi_size_t)vsi_nn_TypeGetBytes(bbox_tensor->attr.dtype.vx_type);
    vsi_size_t stride_conf = (vsi_size_t)vsi_nn_TypeGetBytes(conf_tensor->attr.dtype.vx_type);
    vsi_size_t stride_landms = (vsi_size_t)vsi_nn_TypeGetBytes(landms_tensor->attr.dtype.vx_type);

    if (stride_bbox == 0) stride_bbox = sizeof(float);
    if (stride_conf == 0) stride_conf = sizeof(float);
    if (stride_landms == 0) stride_landms = sizeof(float);

    int num_boxes = sz_bbox / sizeof(float); // 16800
    int num_conf = sz_conf / stride_conf;      //16800
    int num_landmarks = sz_landms / (10 * sizeof(float)); // 4200

    float *tensor_bbox_data = vsi_nn_ConvertTensorToFloat32Data(graph, bbox_tensor);
    float *tensor_conf_data = vsi_nn_ConvertTensorToFloat32Data(graph, conf_tensor);
    float *tensor_landms_data = vsi_nn_ConvertTensorToFloat32Data(graph, landms_tensor);
    if (!tensor_bbox_data || !tensor_conf_data || !tensor_landms_data) {
        free(tensor_bbox_data);
        free(tensor_conf_data);
        free(tensor_landms_data);
        return;
    }

    //generate prior box
    const int image_width = IMAGE_WIDTH;
    const int image_height = IMAGE_HEIGHT;
    std::vector<Anchor> anchors = generate_prior_boxes(image_width, image_height, stride_list, min_sizes, clip);

    std::vector<float> scale = {
        static_cast<float>(IMAGE_WIDTH), // Width
        static_cast<float>(IMAGE_HEIGHT), // Height
        static_cast<float>(IMAGE_WIDTH), // Width (again for some reason)
        static_cast<float>(IMAGE_HEIGHT)  // Height (again for some reason)
    };

    // decode bounding boxes
    std::vector<Prediction> locs(num_boxes);
    for (int i = 0; i < num_boxes; ++i) {
        locs[i].c_x = tensor_bbox_data[i * 4 + 0];
        locs[i].c_y = tensor_bbox_data[i * 4 + 1];
        locs[i].w = tensor_bbox_data[i * 4 + 2];
        locs[i].h = tensor_bbox_data[i * 4 + 3];
    } 

    std::vector<Confidence> confs(num_conf);
    for (int i = 0; i < num_conf; ++i) {
        confs[i].score = tensor_conf_data[i * 2 + 1];
    }

    std::vector<Landmark> landmarks(num_landmarks);
    for (int i = 0; i < num_landmarks; ++i) {
        landmarks[i].points.resize(5);
        for (int j = 0; j < 5; ++j) {
            landmarks[i].points[j].x = tensor_landms_data[i * 10 + j * 2];
            landmarks[i].points[j].y = tensor_landms_data[i * 10 + j * 2 + 1];
        }
    }  

    //decode bounding box
    float resize = 1.0f;
    std::vector<BoundingBox> boxes = decode_boxes(locs, anchors, variances);
    for (auto& box : boxes) {
        box.x = box.x * scale[0] / resize;
        box.y = box.y * scale[1] / resize;
        box.w = box.w * scale[2] / resize;
        box.h = box.h * scale[3] / resize;  
    }

    //decode landmarks   
    std::vector<std::vector<float>> landms = decode_landmarks(landmarks, anchors, variances);

    std::vector<float> scale1 = {
        static_cast<float>(IMAGE_HEIGHT), // Width for x coordinates
        static_cast<float>(IMAGE_HEIGHT), // Height for y coordinates
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT),
        static_cast<float>(IMAGE_HEIGHT)
    };

    for (size_t i = 0; i < landms.size(); ++i) {
        for (int j = 0; j < 5; ++j) {
            landms[i][2 * j]     = landms[i][2 * j] * scale1[2 * j] / resize;     // x
            landms[i][2 * j + 1] = landms[i][2 * j + 1] * scale1[2 * j + 1] / resize; //y
        }
    }

    std::vector<float> filtered_scores; //score
    std::vector<BoundingBox> filtered_boxes; //bouding box
    std::vector<Landmark> filtered_landms; //landmarks
    std::vector<int> inds; 
    for (int i = 0; i < num_conf; ++i) {
        if (confs[i].score > confidence_threshold) {
            inds.push_back(i);
        }
    }

    // use inds to filter boxes、landmarks and scores
    for (size_t i : inds) {
        BoundingBox converted_box;
        converted_box.x = boxes[i].x; //top-left x
        converted_box.y = boxes[i].y; //top-left y
        converted_box.w = boxes[i].x + boxes[i].w; //bottom right x
        converted_box.h = boxes[i].y + boxes[i].h; //bottom right y        
        filtered_boxes.push_back(converted_box);
        filtered_scores.push_back(confs[i].score);
        if (i < landmarks.size()) {
            filtered_landms.push_back(landmarks[i]);
        }        
    } 

    //sort top-K
    std::vector<int> order(filtered_scores.size());
    std::iota(order.begin(), order.end(), 0);
    std::sort(order.begin(), order.end(), [&](int a, int b) {
        return filtered_scores[a] > filtered_scores[b];
    });

    //top_k
    size_t top_k = std::min(static_cast<size_t>(keep_top_k), order.size());
    order.resize(top_k);

    std::vector<BoundingBox> top_boxes;
    std::vector<Landmark> top_landmarks;
    std::vector<float> top_scores;

    for (int i : order) {
        top_boxes.push_back(filtered_boxes[i]);
        //top_landmarks.push_back(filtered_landms[i]);
        top_scores.push_back(filtered_scores[i]);
    }

    //use top_boxes and top_scores to do NMS
    std::vector<cv::Rect> rect_boxes;
    for (const auto& box : top_boxes) {
        cv::Rect rect(static_cast<int>(box.x), static_cast<int>(box.y), static_cast<int>(box.w), static_cast<int>(box.h));
        rect_boxes.push_back(rect);
    }  

    //NMS
    std::vector<int> keep;
    apply_nms(rect_boxes, top_scores, nms_threshold, keep);

    std::vector<FaceObject> detected_faces;
    for (int idx : keep) {
        
        FaceObject face;
        face.rect = rect_boxes[idx];
        face.score = top_scores[idx];
        if (face.score > vis_thres) 
        {
            detected_faces.push_back(face);
        }
    }


    //save top-K detect result
    size_t final_top_k = std::min(static_cast<size_t>(keep_top_k), detected_faces.size());
    faces.resize(final_top_k);

    for (size_t i = 0; i < final_top_k; ++i) {
        faces[i] = detected_faces[i];
    }    

    free(tensor_bbox_data);
    free(tensor_conf_data);
    free(tensor_landms_data);

    return;
}
//End by yingwei


// 計算歐幾里得範數的輔助函數
void Target_database_norm(const std::vector<float>& x, const std::vector<float>& y, float& norm_xy, float& norm_yy) {
    norm_xy = 0.0f;
    norm_yy = 0.0f;
    
    for (size_t i = 0; i < x.size(); i++) {
        norm_xy += x[i] * y[i];
        norm_yy += y[i] * y[i];
    }
}

std::pair<std::vector<std::string>, std::vector<float>> compare(float* target, 
                                                               const std::vector<std::vector<float>>& itriDataDataset, 
                                                               float threshold, 
                                                               size_t featureSize, 
                                                               const std::vector<float>& featureNormList,
                                                               const std::vector<std::string>& names) 
{
    std::vector<std::string> nameList;
    std::vector<float> threshList;

    // Print the number of elements in target and their values
#if 0    
    std::cout << "target array size: " << featureSize << std::endl;
    std::cout << "target values: ";
    for (size_t i = 0; i < featureSize; ++i) {
        std::cout << target[i] << " ";
    }
    std::cout << std::endl;    
#endif

    for (size_t i = 0; i < itriDataDataset.size(); i++) {
        const float* Tface_feature = target;

        float maximal = -1.0f;
        std::string itri_name;

        for (size_t index = 0; index < itriDataDataset.size(); index++) {
            float cosin = 0.0f;
            float norm_xy = 0.0f;
            float norm_yy = 0.0f;

            const std::vector<float>& data_feature = itriDataDataset[index];

            // Calculate cosine similarity
            std::vector<float> data_feature_vec(data_feature.begin(), data_feature.end());
            Target_database_norm(data_feature_vec, std::vector<float>(Tface_feature, Tface_feature + featureSize), norm_xy, norm_yy);

            if (featureNormList[index] != 0 && norm_yy != 0) {
                cosin = norm_xy / std::sqrt(featureNormList[index] * norm_yy);
            }

            if (cosin >= maximal) {
                maximal = cosin;
                std::string p_id = std::to_string(data_feature[featureSize]);
                try {
                    itri_name = names[std::stoi(p_id) - 1];
                } catch (const std::invalid_argument& e) {
                    std::cerr << "Invalid ID: " << p_id << std::endl;
                    itri_name = "Unknown";
                } catch (const std::out_of_range& e) {
                    std::cerr << "ID out of range: " << p_id << std::endl;
                    itri_name = "Unknown";
                }
            }

            // If we find a high enough cosine similarity (e.g. > 0.9), we can stop checking further.
            if (cosin >= 0.9f) {
                break;  // Early exit from the loop if similarity is sufficiently high
            }
        }

        // Only add the name if maximal cosine is above threshold
        if (maximal > threshold) {
            nameList.push_back(itri_name.substr(0, itri_name.find("_"))); // Extract name
            //std::cout << "Final name added: " << itri_name.substr(0, itri_name.find("_")) << " with maximal: " << maximal << std::endl;
        } else {
            nameList.push_back("Unknown");
            //std::cout << "Maximal cosine below threshold: " << maximal << ", added 'Unknown'" << std::endl;
        }
        threshList.push_back(maximal);
    }

    return {nameList, threshList};
}
#if 0
static void post_proc_process_resnet34(vsi_nn_graph_t *graph,
                               cv::Mat &original_image,
                               FaceObject& face, 
                               const std::vector<std::vector<float>>& itriDataDataset, 
                               const std::vector<float>& featureNormList, 
                               const std::vector<std::string>& names)                              
{    
    // 1. get tensor 
    vsi_nn_tensor_t *features_tensor = vsi_nn_GetTensor(graph, graph->output.tensors[0]);

    // 2. get tensor size
    vsi_size_t sz_features = 1;
    for (uint32_t i = 0; i < features_tensor->attr.dim_num; i++) {
        sz_features *= features_tensor->attr.size[i];
    }

    vsi_size_t stride_features = (vsi_size_t)vsi_nn_TypeGetBytes(features_tensor->attr.dtype.vx_type);
    if (stride_features == 0) stride_features = sizeof(float);

    int num_features = sz_features / stride_features;

    float *tensor_features_data = vsi_nn_ConvertTensorToFloat32Data(graph, features_tensor);
    if (!tensor_features_data) {
        return;
    }

    //std::cout << "-----stride_features: " << stride_features << std::endl; //2 (float16)
    //std::cout << "-----sz_features: " << sz_features << std::endl; //128

    // 3. compare function
    //name_list = compare(tensor_features_data, itriDataDataset, OPT_thrshold, FRC_feature_size, featureNormList, names);
    auto result = compare(tensor_features_data, itriDataDataset, OPT_thrshold, FRC_feature_size, featureNormList, names);
    std::vector<std::string> name_list = result.first; // get name list
    std::vector<float> thresh_list = result.second; // get threshold list    

    if (!name_list.empty()) 
    {
        //face.name = name_list[0];
        auto max_it = std::max_element(thresh_list.begin(), thresh_list.end());
        size_t max_index = std::distance(thresh_list.begin(), max_it);
        face.name = name_list[max_index]; 
        face.threshold = thresh_list[max_index];               
    } else {
        face.name = "Unknown";
        face.threshold = 0.0f;
    }

    // print result
    std::cout << "Detected name: " << face.name << ", Threshold: " << face.threshold << std::endl;

    free(tensor_features_data);
    tensor_features_data = nullptr;
    return;    
}
#endif
static void save_output_data(vsi_nn_graph_t *graph)
{
    uint32_t i;
#define _DUMP_FILE_LENGTH 1028
#define _DUMP_SHAPE_LENGTH 128
    char filename[_DUMP_FILE_LENGTH] = {0}, shape[_DUMP_SHAPE_LENGTH] = {0};
    vsi_nn_tensor_t *tensor;

    for(i = 0; i < graph->output.num; i++)
    {
        tensor = vsi_nn_GetTensor(graph, graph->output.tensors[i]);
        vsi_nn_ShapeToString( tensor->attr.size, tensor->attr.dim_num,
            shape, _DUMP_SHAPE_LENGTH, FALSE );
        snprintf(filename, _DUMP_FILE_LENGTH, "output%u_%s.dat", i, shape);
        vsi_nn_SaveTensorToBinary(graph, tensor, filename);

    }
}

static vsi_bool get_top
    (
    float *pfProb,
    float *pfMaxProb,
    vsi_size_t *pMaxClass,
    vsi_size_t outputCount,
    vsi_size_t topNum
    )
{
    vsi_size_t i, j, k;

    #define MAX_TOP_NUM 20
    if (topNum > MAX_TOP_NUM) return FALSE;

    memset(pfMaxProb, 0xfe, sizeof(float) * topNum);
    memset(pMaxClass, 0xff, sizeof(vsi_size_t) * topNum);

    for (j = 0; j < topNum; j++)
    {
        for (i=0; i<outputCount; i++)
        {
            for (k=0; k < topNum; k ++)
            {
                if(i == pMaxClass[k])
                    break;
            }

            if (k != topNum)
                continue;

            if (pfProb[i] > *(pfMaxProb+j))
            {
                *(pfMaxProb+j) = pfProb[i];
                *(pMaxClass+j) = i;
            }
        }
    }

    return TRUE;
}

static vsi_status show_top5
    (
    vsi_nn_graph_t *graph,
    vsi_nn_tensor_t *tensor
    )
{
    vsi_status status = VSI_FAILURE;
    vsi_size_t i,sz,stride;
    float *buffer = NULL;
    uint8_t *tensor_data = NULL;
    vsi_size_t MaxClass[5];
    float fMaxProb[5];
    vsi_size_t topk = 5;

    sz = 1;
    for(i = 0; i < tensor->attr.dim_num; i++)
    {
        sz *= tensor->attr.size[i];
    }

    if(topk > sz)
        topk = sz;

    stride = (vsi_size_t)vsi_nn_TypeGetBytes(tensor->attr.dtype.vx_type);
    if(stride == 0)
    {
        stride = 1;
    }

    tensor_data = (uint8_t *)vsi_nn_ConvertTensorToData(graph, tensor);
    buffer = (float *)malloc(sizeof(float) * sz);


    for(i = 0; i < sz; i++)
    {
        status = vsi_nn_DtypeToFloat32(&tensor_data[stride * i], &buffer[i], &tensor->attr.dtype);
    }

    if (!get_top(buffer, fMaxProb, MaxClass, sz, topk))
    {
        printf("Fail to show result.\n");
        goto final;
    }

    printf(" --- Top%d ---\n", topk);
    for(i = 0; i< topk; i++)
    {
        printf("%3d: %8.6f\n", MaxClass[i], fMaxProb[i]);
    }

    status = VSI_SUCCESS;

final:
    if(tensor_data)vsi_nn_Free(tensor_data);
    if(buffer)free(buffer);
    return status;
}

vsi_status vnn_PostProcessFacedetector3Uint8(vsi_nn_graph_t *graph, std::vector<FaceObject>& faces)
{

#if DETECT_RESULT_IMPL
    post_proc_process(graph, faces);
#else
    vsi_status status = VSI_FAILURE;

    /* Show the top5 result */
    status = show_top5(graph, vsi_nn_GetTensor(graph, graph->output.tensors[0]));
    TEST_CHECK_STATUS(status, final);

    /* Save all output tensor data to txt file */
    save_output_data(graph);

final:
#endif
    return VSI_SUCCESS;
}
#if 0
//Add by yingwei for integration, 20241108
vsi_status vnn_PostProcessResnet34Fp16(vsi_nn_graph_t *graph,
                                        cv::Mat &original_image,
                                        FaceObject& face,
                                        const std::vector<std::vector<float>>& itriDataDataset,
                                        const std::vector<float>& featureNormList,
                                        const std::vector<std::string>& names)                                        
{
    post_proc_process_resnet34(graph, original_image, face, itriDataDataset, featureNormList, names);

    return VSI_SUCCESS;
}
//End by yingwei for integration, 20241108
#endif


